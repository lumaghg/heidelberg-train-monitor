{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08139850",
   "metadata": {},
   "source": [
    "# Preprocess static data from DB Timetables API\n",
    "\n",
    "- script runs hourly\n",
    "- to be able to know about every train that is currently on the way, we need data for current_time +- time of the longest trip between stations without stopping, which is 4h (FFM-Berlin Sprinter). Data should last for 1 hour before updating. Therefore we need to request current hour, the 4 hours before that and the 4 hours after that = 9 hours. \n",
    "Steps:\n",
    "- delete data from timetable that is for an hour before current hour - 4. \n",
    "- request the timetable from every relevant station, and parse the xmls into a timetable while filtering for Fernverkehr (category in [ICE, IC, EC, NJ ...]). Note which date/hour was used to make the request. \n",
    "- artificially add departure and arrival dates where missing\n",
    "- sort by I. tripid 2. departure time / stop order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d28c235",
   "metadata": {},
   "source": [
    "### helper functions for handling db dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea6a6813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250810\n",
      "2508101222\n",
      "2025-08-10\n",
      "2025-08-10 12:22:00\n",
      "('250810', '12')\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from dotenv import load_dotenv\n",
    "from os import getenv\n",
    "import pandas as pd\n",
    "import ratelimit\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "PLANNED_STOPTIMES_PATH = 'stoptimes_planned.csv'\n",
    "STATIONS_PATH = './static/stations.csv'\n",
    "REQUEST_LOG_PATH = './request_log.csv'\n",
    "FV_CATEGORIES = [\"IC\", \"EC\", \"ICE\", \"FLX\", \"WB\", \"RJ\", \"RJX\", \"ECE\", \"EST\", \"TGV\", \"NJ\", \"EN\", \"ES\", \"DN\", \"D\", \"SJ\"]\n",
    "\n",
    "# chatgpt generiert lol\n",
    "import datetime\n",
    "def dateToDBDate(date: datetime.date) -> str:\n",
    "    \"\"\"\n",
    "    Wandelt ein datetime.date Objekt in einen DB-Date-String \"YYMMDD\" um.\n",
    "    \"\"\"\n",
    "    return date.strftime(\"%y%m%d\")\n",
    "\n",
    "\n",
    "def datetimeToDBDatetime(dt: datetime.datetime) -> str:\n",
    "    \"\"\"\n",
    "    Wandelt ein datetime.datetime Objekt in einen DB-Datetime-String \"YYMMDDHHMM\" um.\n",
    "    \"\"\"\n",
    "    return dt.strftime(\"%y%m%d%H%M\")\n",
    "\n",
    "\n",
    "def DBDatetimeToDatetime(dbDate: str) -> datetime.datetime:\n",
    "    \"\"\"\n",
    "    Wandelt einen DB-Datetime-String \"YYMMDDHHMM\" in ein datetime.datetime Objekt um.\n",
    "    \"\"\"\n",
    "    return datetime.datetime.strptime(dbDate, \"%y%m%d%H%M\")\n",
    "\n",
    "\n",
    "def DBDateToDate(dbDate: str) -> datetime.date:\n",
    "    \"\"\"\n",
    "    Wandelt einen DB-Date-String \"YYMMDD\" in ein datetime.date Objekt um.\n",
    "    \"\"\"\n",
    "    return datetime.datetime.strptime(dbDate, \"%y%m%d\").date()\n",
    "\n",
    "def datetimeToDBDateAndHourTuple(dt: datetime.datetime):\n",
    "    date = dt.strftime(\"%y%m%d\")\n",
    "    hour = dt.strftime(\"%H\")\n",
    "    return (date, hour)\n",
    "    \n",
    "       \n",
    "print(dateToDBDate(datetime.date(2025, 8, 10)))\n",
    "print(datetimeToDBDatetime(datetime.datetime(2025, 8, 10, 12, 22)))\n",
    "print(DBDateToDate(\"250810\"))\n",
    "print(DBDatetimeToDatetime(\"2508101222\"))\n",
    "print(datetimeToDBDateAndHourTuple(datetime.datetime(2025, 8, 10, 12, 22)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7a1e15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def extract_tripid_from_stopid(stop_id: str):\n",
    "                \n",
    "    has_dash = True if stop_id.startswith(\"-\") else False\n",
    "\n",
    "    trip_id = None\n",
    "\n",
    "    if has_dash:\n",
    "        # if stop id has dash, the first split result will be empty\n",
    "        trip_id = stop_id.split(\"-\")[1]\n",
    "        trip_id = f\"-{trip_id}\"\n",
    "    else:\n",
    "        trip_id = stop_id.split(\"-\")[0]\n",
    "    return trip_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c95349d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('250914', '07'), ('250914', '08'), ('250914', '09'), ('250914', '10'), ('250914', '11'), ('250914', '12'), ('250914', '13'), ('250914', '14'), ('250914', '15')]\n"
     ]
    }
   ],
   "source": [
    "# calculate which times need to be requested\n",
    "\n",
    "date_hour_tuples_to_request = []\n",
    "\n",
    "current_datetime = datetime.datetime.today()\n",
    "\n",
    "for hour_offset in range(-4,5):\n",
    "    datetime_to_request = current_datetime + datetime.timedelta(hours=hour_offset)\n",
    "    date_hour_tuple = datetimeToDBDateAndHourTuple(datetime_to_request)\n",
    "    date_hour_tuples_to_request.append(datetimeToDBDateAndHourTuple(datetime_to_request))\n",
    "\n",
    "\n",
    "print(date_hour_tuples_to_request)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "467f89b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      station_name station_uic\n",
      "0      Hamburg Hbf     8002549\n",
      "1  Hamburg-Harburg     8000147\n",
      "2         Lüneburg     8000238\n",
      "3           Uelzen     8000168\n",
      "4            Celle     8000064\n",
      "5     Hannover Hbf     8000152\n"
     ]
    }
   ],
   "source": [
    "# load stations that need to be requested\n",
    "df_stations = pd.read_csv(STATIONS_PATH, dtype=str).dropna(how='all')\n",
    "print(df_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34c371ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requesting Hamburg Hbf\n",
      "fetching 250914 / 07:00 / Hamburg Hbf\n",
      "fetching 250914 / 08:00 / Hamburg Hbf\n",
      "fetching 250914 / 09:00 / Hamburg Hbf\n",
      "fetching 250914 / 10:00 / Hamburg Hbf\n",
      "fetching 250914 / 11:00 / Hamburg Hbf\n",
      "fetching 250914 / 12:00 / Hamburg Hbf\n",
      "fetching 250914 / 13:00 / Hamburg Hbf\n",
      "fetching 250914 / 14:00 / Hamburg Hbf\n",
      "fetching 250914 / 15:00 / Hamburg Hbf\n",
      "requesting Hamburg-Harburg\n",
      "fetching 250914 / 07:00 / Hamburg-Harburg\n",
      "fetching 250914 / 08:00 / Hamburg-Harburg\n",
      "fetching 250914 / 09:00 / Hamburg-Harburg\n",
      "fetching 250914 / 10:00 / Hamburg-Harburg\n",
      "fetching 250914 / 11:00 / Hamburg-Harburg\n",
      "fetching 250914 / 12:00 / Hamburg-Harburg\n",
      "fetching 250914 / 13:00 / Hamburg-Harburg\n",
      "fetching 250914 / 14:00 / Hamburg-Harburg\n",
      "fetching 250914 / 15:00 / Hamburg-Harburg\n",
      "requesting Lüneburg\n",
      "fetching 250914 / 07:00 / Lüneburg\n",
      "fetching 250914 / 08:00 / Lüneburg\n",
      "fetching 250914 / 09:00 / Lüneburg\n",
      "fetching 250914 / 10:00 / Lüneburg\n",
      "fetching 250914 / 11:00 / Lüneburg\n",
      "fetching 250914 / 12:00 / Lüneburg\n",
      "fetching 250914 / 13:00 / Lüneburg\n",
      "fetching 250914 / 14:00 / Lüneburg\n",
      "fetching 250914 / 15:00 / Lüneburg\n",
      "requesting Uelzen\n",
      "fetching 250914 / 07:00 / Uelzen\n",
      "fetching 250914 / 08:00 / Uelzen\n",
      "fetching 250914 / 09:00 / Uelzen\n",
      "fetching 250914 / 10:00 / Uelzen\n",
      "fetching 250914 / 11:00 / Uelzen\n",
      "fetching 250914 / 12:00 / Uelzen\n",
      "fetching 250914 / 13:00 / Uelzen\n",
      "fetching 250914 / 14:00 / Uelzen\n",
      "fetching 250914 / 15:00 / Uelzen\n",
      "requesting Celle\n",
      "fetching 250914 / 07:00 / Celle\n",
      "fetching 250914 / 08:00 / Celle\n",
      "fetching 250914 / 09:00 / Celle\n",
      "fetching 250914 / 10:00 / Celle\n",
      "fetching 250914 / 11:00 / Celle\n",
      "fetching 250914 / 12:00 / Celle\n",
      "fetching 250914 / 13:00 / Celle\n",
      "fetching 250914 / 14:00 / Celle\n",
      "fetching 250914 / 15:00 / Celle\n",
      "requesting Hannover Hbf\n",
      "fetching 250914 / 07:00 / Hannover Hbf\n",
      "[RateLimit] Limit erreicht (58/58s). Warte auf freien Slot...\n",
      "[RateLimit] Slot frei, Request wird gesendet.\n",
      "fetching 250914 / 08:00 / Hannover Hbf\n",
      "fetching 250914 / 09:00 / Hannover Hbf\n",
      "fetching 250914 / 10:00 / Hannover Hbf\n",
      "fetching 250914 / 11:00 / Hannover Hbf\n",
      "fetching 250914 / 12:00 / Hannover Hbf\n",
      "fetching 250914 / 13:00 / Hannover Hbf\n",
      "fetching 250914 / 14:00 / Hannover Hbf\n",
      "fetching 250914 / 15:00 / Hannover Hbf\n"
     ]
    }
   ],
   "source": [
    "# request and process timetables\n",
    "import requests\n",
    "import xmltodict\n",
    "import time\n",
    "import os.path as path\n",
    "\n",
    "# load envs\n",
    "db_timetables_base_url = getenv(\"db_timetables_base_url\")\n",
    "db_client_id = getenv(\"db_client_id\")\n",
    "db_client_secret = getenv(\"db_client_secret\")\n",
    "\n",
    "\n",
    "\n",
    "# delete stop times belonging to hours more than 4 hours ago (request timestamp marks the hour in which the stoptime happens)\n",
    "df_stoptimes = None\n",
    "\n",
    "four_hours_ago_tuple = datetimeToDBDateAndHourTuple(datetime.datetime.now() - datetime.timedelta(hours=4))\n",
    "request_timestamp_four_hours_ago = f\"{four_hours_ago_tuple[0]}{four_hours_ago_tuple[1]}\"\n",
    "\n",
    "if path.exists(PLANNED_STOPTIMES_PATH):\n",
    "    df_stoptimes = pd.read_csv(PLANNED_STOPTIMES_PATH, dtype=str).dropna(how='all')\n",
    "    df_stoptimes = df_stoptimes.drop(df_stoptimes[df_stoptimes['request_timestamp'] < request_timestamp_four_hours_ago].index)\n",
    "    \n",
    "else:\n",
    "    df_stoptimes = pd.DataFrame(columns=['trip_id', 'category', 'number', 'station_name', 'arrival_planned_dbdatetime', 'departure_planned_dbdatetime', 'arrival_ppth', 'departure_ppth', 'request_timestamp','station_uic'])\n",
    "\n",
    "\n",
    "\n",
    "# load request log or create if not exists and delete entries older than 9 hours\n",
    "df_request_log = None\n",
    "if(path.exists(REQUEST_LOG_PATH)):\n",
    "    df_request_log = pd.read_csv(REQUEST_LOG_PATH, dtype=str).dropna(how='all')\n",
    "    df_request_log = df_request_log.drop(df_request_log[df_request_log['request_timestamp'] < request_timestamp_four_hours_ago].index)\n",
    "else:\n",
    "    df_request_log = pd.DataFrame(columns=['request_timestamp', 'station_uic'])\n",
    "    \n",
    "\n",
    "xml_timestamp_tuple = []\n",
    "\n",
    "request_counter = 0\n",
    "\n",
    "\n",
    "for index, station_row in df_stations.iterrows():\n",
    "\n",
    "    station_uic = station_row['station_uic']\n",
    "    station_name = station_row['station_name']\n",
    "    \n",
    "    print(f\"requesting {station_name}\")\n",
    "        \n",
    "    timetable_rows_for_current_station = []\n",
    "        \n",
    "    for date_hour_tuple in date_hour_tuples_to_request:\n",
    "        try:\n",
    "            date_to_request = date_hour_tuple[0] \n",
    "            hour_to_request = date_hour_tuple[1] \n",
    "            request_timestamp = f\"{date_to_request}{hour_to_request}\"\n",
    "            \n",
    "            # check if station / request_timestamp combination has already been fetched\n",
    "            rows_for_timestamp_and_station = df_request_log[(df_request_log['request_timestamp'] == request_timestamp) & (df_request_log['station_uic'] == station_uic)]\n",
    "            no_rows_for_timestamp_and_station = rows_for_timestamp_and_station.shape[0]\n",
    "            \n",
    "            \n",
    "            if no_rows_for_timestamp_and_station > 0:\n",
    "                print(f\"{date_to_request} / {hour_to_request}:00 / {station_name} already present\")\n",
    "                # already fetched\n",
    "                continue\n",
    "            \n",
    "            # respect rate limiting\n",
    "            ratelimit.wait_for_slot()\n",
    "            \n",
    "            \n",
    "            print(f\"fetching {date_to_request} / {hour_to_request}:00 / {station_name}\")\n",
    "            \n",
    "            # prepare request headers\n",
    "            auth_headers = {\n",
    "                'DB-Client-Id': db_client_id,\n",
    "                'DB-Api-Key': db_client_secret\n",
    "            }\n",
    "            \n",
    "            # {hour:02} means print hour, fill (0) up to 2 (2) digits\n",
    "            url = f\"{db_timetables_base_url}/plan/{station_uic}/{date_to_request}/{hour_to_request}\"\n",
    "            \n",
    "            \n",
    "            response = requests.get(url=url, headers=auth_headers)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"skipping hour {hour_to_request}, station {station_uic}, {response.status_code}\")\n",
    "                continue\n",
    "            \n",
    "            # note which stations / times have already been requested\n",
    "            df_request_log = pd.concat([df_request_log, pd.DataFrame(data={'request_timestamp': [request_timestamp], 'station_uic': [station_uic]})])\n",
    "            \n",
    "            \n",
    "            # process response\n",
    "            timetable_dict = xmltodict.parse(response.content)\n",
    "            if timetable_dict['timetable'] is None:\n",
    "                print(f'empty timetable: skipping hour {hour_to_request}, station {station_uic}')\n",
    "                continue\n",
    "            \n",
    "            timetable_stops = timetable_dict['timetable']['s']\n",
    "            \n",
    "            # if there is only one trip in the requested hour, the xml parser parses the timetable stop entry into a dict rather than a list\n",
    "            if not isinstance(timetable_stops, list):\n",
    "                timetable_stops = [timetable_stops]\n",
    "            \n",
    "            for timetable_stop in timetable_stops:\n",
    "                try:\n",
    "                    # category (e.g. ICE, RE, S)\n",
    "                    trip_label = timetable_stop['tl']\n",
    "                    category = trip_label['@c']\n",
    "                    number = trip_label['@n']\n",
    "                    \n",
    "                    # for some idiotic reason, the ids can start with a dash while also being separated by a dash\n",
    "                    stop_id = timetable_stop['@id']\n",
    "                    \n",
    "                    trip_id = extract_tripid_from_stopid(stop_id)\n",
    "                    \n",
    "                    \n",
    "                    # only save Fernverkehr (not using filter flag because NJ dont have them)\n",
    "                    if category not in FV_CATEGORIES:\n",
    "                        continue\n",
    "                    \n",
    "                    # arrival\n",
    "                    arrival_planned_dbdatetime = None\n",
    "                    arrival_ppth = None\n",
    "                    \n",
    "                    if 'ar' in timetable_stop:\n",
    "                        arrival = timetable_stop['ar']\n",
    "                        arrival_planned_dbdatetime = arrival['@pt']\n",
    "                        arrival_ppth = arrival['@ppth']\n",
    "                        \n",
    "                    # departure\n",
    "                    departure_planned_dbdatetime = None\n",
    "                    \n",
    "                    if 'dp' in timetable_stop:\n",
    "                        departure = timetable_stop['dp']\n",
    "                        departure_planned_dbdatetime = departure['@pt']   \n",
    "                        departure_ppth = departure['@ppth']\n",
    "                    \n",
    "                            \n",
    "                    stoptimes_row = pd.DataFrame(data={'trip_id': [trip_id], 'category':[category], 'number': [number], 'station_name':[station_name], 'arrival_planned_dbdatetime': [arrival_planned_dbdatetime], 'departure_planned_dbdatetime':[departure_planned_dbdatetime], 'arrival_ppth': [arrival_ppth], 'departure_ppth': [departure_ppth], 'request_timestamp': [request_timestamp], 'station_uic': station_uic})\n",
    "\n",
    "                    df_stoptimes = pd.concat([df_stoptimes, stoptimes_row], ignore_index=True)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"error while processing timetable stop\")\n",
    "                    print(e)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"error while fetching or converting {date_to_request} / {hour_to_request}:00 / {station_name}\")\n",
    "            print(e)\n",
    "    \n",
    "    # after every station postprocess and save:\n",
    "    \n",
    "    # remove duplicates\n",
    "    # duplicates can occur when a train arrives before and departs after the full hour, because in this case the train will be included in both slices\n",
    "\n",
    "    df_stoptimes = df_stoptimes.drop_duplicates(subset=['trip_id', 'station_uic', 'departure_planned_dbdatetime'])\n",
    "    \n",
    "\n",
    "    \n",
    "    # sort\n",
    "    df_stoptimes = df_stoptimes.sort_values(by=['trip_id','departure_planned_dbdatetime'])\n",
    "    \n",
    "    # duplicate departures and arrivals to prepare for realtime changes\n",
    "    df_stoptimes['arrival_actual_dbdatetime'] = df_stoptimes.loc[:,'arrival_planned_dbdatetime']\n",
    "    df_stoptimes['departure_actual_dbdatetime'] = df_stoptimes.loc[:,'departure_planned_dbdatetime']\n",
    "    \n",
    "    # save after every station \n",
    "    df_stoptimes.to_csv(PLANNED_STOPTIMES_PATH, index=False)\n",
    "    df_request_log.to_csv(REQUEST_LOG_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3611706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort dataframe by tripid and departure\n",
    "\n",
    "df_stoptimes = df_stoptimes.sort_values(by=['trip_id','departure_planned_dbdatetime'])\n",
    "\n",
    "df_stoptimes.to_csv(PLANNED_STOPTIMES_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df759122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
