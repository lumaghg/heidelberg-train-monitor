{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99c91e9e",
   "metadata": {},
   "source": [
    "# Compute Statuscodes\n",
    "1. check where each train is at the moment\n",
    "2. collect trip ids of trains that are somewhere on the map right now\n",
    "3. check between which stations each trip is\n",
    "4. find the stretch each trip is on\n",
    "5. calculate the position of each train on their respective stretch\n",
    "6. lookup the stretch segment each stretch is on\n",
    "7. put the statuscode together and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "75b146c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250810\n",
      "2508101222\n",
      "2025-08-10\n",
      "2025-08-10 12:22:00\n",
      "('250810', '12')\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from dotenv import load_dotenv\n",
    "from os import getenv\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "STOPTIMES_PATH = 'stoptimes.csv'\n",
    "STRETCHES_PATH = './static/stretches.csv'\n",
    "STRETCH_SEGMENTS_PATH = './static/stretch_segments.csv'\n",
    "STATIONS_PATH = './static/stations.csv'\n",
    "FOCUS_SIGNATURES_PATH = './static/focus_signatures.csv'\n",
    "TRIPID_STRETCHID_PATH = './tripid_stretchid.csv'\n",
    "\n",
    "# chatgpt generiert lol\n",
    "import datetime\n",
    "def dateToDBDate(date: datetime.date) -> str:\n",
    "    \"\"\"\n",
    "    Wandelt ein datetime.date Objekt in einen DB-Date-String \"YYMMDD\" um.\n",
    "    \"\"\"\n",
    "    return date.strftime(\"%y%m%d\")\n",
    "\n",
    "\n",
    "def datetimeToDBDatetime(dt: datetime.datetime) -> str:\n",
    "    \"\"\"\n",
    "    Wandelt ein datetime.datetime Objekt in einen DB-Datetime-String \"YYMMDDHHMM\" um.\n",
    "    \"\"\"\n",
    "    return dt.strftime(\"%y%m%d%H%M\")\n",
    "\n",
    "\n",
    "def DBDatetimeToDatetime(dbDate: str) -> datetime.datetime:\n",
    "    \"\"\"\n",
    "    Wandelt einen DB-Datetime-String \"YYMMDDHHMM\" in ein datetime.datetime Objekt um.\n",
    "    \"\"\"\n",
    "    return datetime.datetime.strptime(dbDate, \"%y%m%d%H%M\")\n",
    "\n",
    "\n",
    "def DBDateToDate(dbDate: str) -> datetime.date:\n",
    "    \"\"\"\n",
    "    Wandelt einen DB-Date-String \"YYMMDD\" in ein datetime.date Objekt um.\n",
    "    \"\"\"\n",
    "    return datetime.datetime.strptime(dbDate, \"%y%m%d\").date()\n",
    "\n",
    "def datetimeToDBDateAndHourTuple(dt: datetime.datetime):\n",
    "    date = dt.strftime(\"%y%m%d\")\n",
    "    hour = dt.strftime(\"%H\")\n",
    "    return (date, hour)\n",
    "    \n",
    "       \n",
    "print(dateToDBDate(datetime.date(2025, 8, 10)))\n",
    "print(datetimeToDBDatetime(datetime.datetime(2025, 8, 10, 12, 22)))\n",
    "print(DBDateToDate(\"250810\"))\n",
    "print(DBDatetimeToDatetime(\"2508101222\"))\n",
    "print(datetimeToDBDateAndHourTuple(datetime.datetime(2025, 8, 10, 12, 22)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "06a0a8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stoptimes = pd.read_csv(STOPTIMES_PATH, dtype=\"string\", parse_dates=['arrival', \"departure\"]).dropna(how='all')\n",
    "\n",
    "# remove request_timestamp and request_uic because they were only needed in the df_stoptimes.csv for the preprocessing\n",
    "# to identify outdated and cached data and during change application to match the changes to the stoptime entries.\n",
    "# But they are not needed anymore and as the stoptimes.csv is only read but not overwritten in this script, they can go\n",
    "df_stoptimes = df_stoptimes.drop(labels=['request_timestamp'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3afddccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 123 active trips\n"
     ]
    }
   ],
   "source": [
    "# find active trip ids\n",
    "\n",
    "current_datetime = datetime.datetime.now()\n",
    "    \n",
    "# train is departed, when the departure time was before now\n",
    "df_stoptimes['has_departed_station'] = df_stoptimes['departure'] < current_datetime\n",
    "\n",
    "# find tripids with one stop time and remove them, as for identifying a position on a stretch at least two stops are needed.\n",
    "tripids_with_one_stoptime_mask = df_stoptimes.groupby(\"trip_id\")[\"trip_id\"].transform(\"count\") == 1\n",
    "df_stoptimes = df_stoptimes.drop(df_stoptimes[tripids_with_one_stoptime_mask].index)\n",
    "\n",
    "# find tripids where all stops have been departed and remove them, as that means the trip has ended\n",
    "tripids_ended_mask = df_stoptimes.groupby(\"trip_id\")[\"has_departed_station\"].transform(\"all\")\n",
    "df_stoptimes = df_stoptimes.drop(df_stoptimes[tripids_ended_mask].index)\n",
    "\n",
    "# find tripids where not any stops have been departed and remove them, as that means the trip has not started yet\n",
    "tripids_not_started_mask = ~df_stoptimes.groupby(\"trip_id\")[\"has_departed_station\"].transform(\"any\")\n",
    "df_stoptimes = df_stoptimes.drop(df_stoptimes[tripids_not_started_mask].index)\n",
    "\n",
    "# only the active trips remain\n",
    "\n",
    "no_active_trips = df_stoptimes['trip_id'].unique().shape[0]\n",
    "print(f\"found {no_active_trips} active trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "455fb184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the two stations, between which each train is traveling (standing at a station until departure counts to being between the two stations. \n",
    "# The stopping time animation is handled by calculating where the train is between the two stations and \n",
    "# standing at the second station simply gets mapped to having travelled 100% of the time)\n",
    "# therefore the previous station is the last of the departed stations and the next station is the first of the undeparted stations\n",
    "\n",
    "previous_stations = df_stoptimes[df_stoptimes['has_departed_station'] == True].groupby(by=['trip_id'], as_index=False).last()\n",
    "next_stations = df_stoptimes[df_stoptimes['has_departed_station'] == False].groupby(by=['trip_id'], as_index=False).first()\n",
    "\n",
    "# has_departed_station now not needed anymore\n",
    "previous_stations = previous_stations.drop(labels=['has_departed_station'], axis=1)\n",
    "next_stations = next_stations.drop(labels=['has_departed_station'], axis=1)\n",
    "\n",
    "df_trip_statuses = pd.merge(how='inner', left=previous_stations, right=next_stations, on=['trip_id', 'category', 'number'], suffixes=(\"_previous\", \"_next\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "244fe194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load graph representation of network\n",
    "# station -> nodes\n",
    "# stretches -> edges\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "stretches = pd.read_csv(STRETCHES_PATH, dtype=str).dropna(how='all')\n",
    "stations = pd.read_csv(STATIONS_PATH, dtype=str).dropna(how='all')\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "# add nodes\n",
    "station_list = list(stations.itertuples(index=False, name=None)) # [(station_name, station_uic)]\n",
    "nodes = [(station[1], {'station_name': station[0]}) for station in station_list]\n",
    "G.add_nodes_from(nodes)\n",
    "\n",
    "# add edges\n",
    "# attraction force is used to draw the graph by defining the attraction force between the two nodes and is the inverted travel time\n",
    "edge_list = list(stretches[['station_uic_from', 'station_uic_to', 'station_name_from','station_name_to','travel_cost','super_name']].itertuples(index=False, name=None)) # [(station_name_from, station_uic_from, station_name_to, station_uic_from, travel_cost, super_name)]\n",
    "edges = [(edge[0], edge[1], {'station_name_from': edge[2], 'station_name_to': edge[3], 'travel_cost': int(edge[4]), 'super_name': edge[5]}) for edge in edge_list]\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2ecf0366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate where the train is\n",
    "import numpy as np\n",
    "\n",
    "# calculate path between the stations, the trip is currently travelling\n",
    "def compute_position_on_graph(row):\n",
    "    previous_station = row['station_uic_previous']\n",
    "    next_station = row['station_uic_next']\n",
    "    previous_station_departure:datetime.datetime = row['departure_previous']\n",
    "    next_station_arrival:datetime.datetime = row['arrival_next']\n",
    "    \n",
    "    shortest_path = nx.shortest_path(G, previous_station, next_station, weight='travel_cost')\n",
    "    \n",
    "    # calculate total travel cost for shortest path\n",
    "    edges = []\n",
    "    total_travel_cost = 0.0\n",
    "    for u, v in zip(shortest_path[:-1], shortest_path[1:]):\n",
    "        travel_cost = int(G[u][v]['travel_cost'])\n",
    "        total_travel_cost += travel_cost\n",
    "        edges.append([u,v,travel_cost])\n",
    "    \n",
    "    # calculate relative travel cost for edge relative to the total cost of the whole path\n",
    "    edges = np.array(edges, dtype=str)\n",
    "    relative_travel_costs = [int(edge[2]) / total_travel_cost for edge in edges]\n",
    "\n",
    "    # cumulative travel costs add up to one, as they were normalized before in relation to total travel cost.\n",
    "    # therefore, the cumulative_relative_travel_costs map to how much progress a trip needs to make on the shortest path to finish a edge of the path.\n",
    "    cumulative_relative_travel_costs = np.cumsum(relative_travel_costs)\n",
    "    \n",
    "    # calculate trip progress on the shortest path\n",
    "    current_time = datetime.datetime.now()\n",
    "    time_elapsed_since_last_stop = current_time - previous_station_departure\n",
    "    trip_travel_time = next_station_arrival - previous_station_departure\n",
    "    trip_progress = time_elapsed_since_last_stop.total_seconds() / trip_travel_time.total_seconds()\n",
    "    \n",
    "    # find the first edge that has not been finished which is the edge currently travelled on\n",
    "    # done by calculating binary array, which returns false for finished (progress < cumcost) and true for finished (progress > cumcost) segments.\n",
    "    # argmax returns the first occurence of the maximum value and 0 in case of no maximum value which is convenient, as the 0th edge is being travelled if\n",
    "    # none are finished and therefore the operation returns in a list full of False \n",
    "    index_of_current_edge = np.argmax(trip_progress < cumulative_relative_travel_costs)\n",
    "    \n",
    "    # with the index, the current edge can be retrieved from the edges\n",
    "    current_edge = edges[index_of_current_edge]\n",
    "    \n",
    "    # to calculate the relative progress on the current edge, the total progress - the relative cost of all finished edges will be divided by the relative cost of the current edge \n",
    "    current_edge_relative_travel_cost = relative_travel_costs[index_of_current_edge]\n",
    "    current_edge_progress_upper_bound = cumulative_relative_travel_costs[index_of_current_edge]\n",
    "    current_edge_progress_lower_bound = current_edge_progress_upper_bound - current_edge_relative_travel_cost\n",
    "    \n",
    "    progress_on_current_edge = (trip_progress - current_edge_progress_lower_bound) / current_edge_relative_travel_cost\n",
    "    \n",
    "    # if the train is standing in the station, progress will show more than 100%, because the time since last departure is longer than \n",
    "    # the time between last departure and next arrival\n",
    "    percentage_on_current_edge = min(int(progress_on_current_edge * 100), 100)\n",
    "    \n",
    "    station_uic_from = current_edge[0]\n",
    "    station_uic_to = current_edge[1]\n",
    "    # find id of current edge in stretches\n",
    "    \n",
    "    travels_in_reverse_direction = False\n",
    "    \n",
    "    current_stretch = stretches[(stretches['station_uic_from'] == station_uic_from) & (stretches['station_uic_to'] == station_uic_to)]\n",
    "    \n",
    "    # stretches are defined one way but work both ways\n",
    "    if len(current_stretch) == 0:\n",
    "        current_stretch = stretches[(stretches['station_uic_to'] == station_uic_from) & (stretches['station_uic_from'] == station_uic_to)]\n",
    "        travels_in_reverse_direction = True\n",
    "    \n",
    "    if len(current_stretch) == 0:\n",
    "        print(f'No Stretch found for edge: {current_edge}')\n",
    "        \n",
    "    current_stretch_id = current_stretch.iloc[0]['stretch_id']\n",
    "    current_stretch_name = current_stretch.iloc[0]['stretch_name']\n",
    "    current_stretch_super_name = current_stretch.iloc[0]['super_name']\n",
    "    \n",
    "    return {'stretch_super_name': current_stretch_super_name,'stretch_name': current_stretch_name,'progress': percentage_on_current_edge, 'stretch_id': current_stretch_id,  'travelling_reverse': travels_in_reverse_direction}\n",
    "    \n",
    "df_trip_statuses['position'] = df_trip_statuses.apply(compute_position_on_graph, axis=1) \n",
    "\n",
    "# arrival and departure times and stations are no longer needed\n",
    "\n",
    "#df_trip_statuses = df_trip_statuses.drop(['station_name_previous','station_uic_previous','arrival_previous','departure_previous','station_name_next','station_uic_next','arrival_next','departure_next'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f12fb151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup row in stretch_id + % to stretch_segment / LED mapping\n",
    "from collections import defaultdict\n",
    "\n",
    "types = defaultdict(lambda: str, lower_bound = \"int\", upper_bound = \"int\")\n",
    "stretch_segments = pd.read_csv(STRETCH_SEGMENTS_PATH, dtype=types).dropna(how='all')\n",
    "\n",
    "# find rows where the progress of the trip fits, can be 1 or 2 if the progress is right on the edge because of both sides inclusive\n",
    "def compute_primary_statuscode(row):\n",
    "    position = row['position']\n",
    "    stretch_id = position['stretch_id']\n",
    "    progress = int(position['progress'])\n",
    "    is_travelling_reverse = position['travelling_reverse']\n",
    "    \n",
    "    # if the train is travelling in the inverse direction, the progress needs to be inverted. Hamburg -> Hannover 20% and Hannover -> Hamburg 80% are the same positions\n",
    "    stretch_position = (100 - progress) if is_travelling_reverse else progress\n",
    "    \n",
    "    # find stretch segments that fit and take the first one, as it is right on the edge between two segments if there are more than one\n",
    "    stretch_id_mask = stretch_segments['stretch_id'] == stretch_id\n",
    "    lower_bound_mask = stretch_segments['lower_bound'] <= stretch_position\n",
    "    upper_bound_mask = stretch_position <= stretch_segments['upper_bound']\n",
    "    \n",
    "    applicable_segments = stretch_segments[stretch_id_mask & lower_bound_mask & upper_bound_mask]\n",
    "    \n",
    "    segment = None\n",
    "    if len(applicable_segments) < 1:\n",
    "        return\n",
    "    else:\n",
    "        segment = applicable_segments.iloc[0]\n",
    "    \n",
    "    statuscode = f\"{segment['stretch_id']}_{segment['segment_number']}\"\n",
    "    \n",
    "    return statuscode\n",
    "\n",
    "# optionally compute statuscode for secondary LED by building list of all segment rows along the path, then group by LED and find the LED before the current one.\n",
    "\n",
    "df_trip_statuses['primary_statuscode'] = df_trip_statuses.apply(compute_primary_statuscode, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "49a93f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute delay\n",
    "# choose arrival_delay_next if the train has not reached the next station, choose departure_delay_next if the train has reached the next station\n",
    "\n",
    "def compute_delay(row):\n",
    "    arrival_next = row['arrival_next']\n",
    "    \n",
    "    # train is still travelling    \n",
    "    if arrival_next > datetime.datetime.now():\n",
    "        return int(row['arrival_delay_next'])\n",
    "    \n",
    "    # train has reached next station\n",
    "    else:\n",
    "        return int(row['departure_delay_next'])     \n",
    "    \n",
    "df_trip_statuses['delay'] = df_trip_statuses.apply(compute_delay, axis=1)\n",
    "\n",
    "# if the memory is needed, drop the old delay columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "dbee0f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add category priority (higher number = higher priority)\n",
    "def compute_category_priority(category: str):\n",
    "\n",
    "    if category in ['ICE']:\n",
    "        return 0\n",
    "    \n",
    "    if category in ['IC']:\n",
    "        return 1\n",
    "\n",
    "    if category in ['EC','FLX','WB', 'RJ', 'RJX', 'ECE', 'EST','TGV', 'NJ','EN','ES','DN','D','SJ']:\n",
    "        return 2\n",
    "    \n",
    "df_trip_statuses['category_priority'] = df_trip_statuses['category'].map(compute_category_priority)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "9f9aeca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# color mapping for animationcodes\n",
    "\n",
    "def get_color_for_category(category: str):\n",
    "    if category in ['IC']:\n",
    "        return \"008F8F\"\n",
    "    \n",
    "    if category in ['EC']:\n",
    "        return \"0000AA\"\n",
    "    \n",
    "    if category in ['ICE']:\n",
    "        return \"ADA869\"\n",
    "    \n",
    "    if category in ['FLX','WB']:\n",
    "        return \"008F00\"\n",
    "    \n",
    "    if category in ['RJ', 'RJX', 'ECE']:\n",
    "        return \"A96000\"\n",
    "    \n",
    "    if category in ['EST','TGV']:\n",
    "        return \"A00000\"\n",
    "    \n",
    "    if category in ['NJ','EN','ES','DN','D','SJ']:\n",
    "        return \"8900AC\"\n",
    "    \n",
    "    return \"FFFF00\"\n",
    "\n",
    "def get_color_for_delay(delay: str):\n",
    "    if delay > 45:\n",
    "        return \"8F0000\"\n",
    "    if delay > 15:\n",
    "        return \"877100\"\n",
    "    else:\n",
    "        return \"328F00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "7273056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build animationcodes\n",
    "\n",
    "def compute_primary_animationcodes(row, color_by: str):\n",
    "    if color_by == 'delay':\n",
    "        color = get_color_for_delay(row['delay'])\n",
    "    else:\n",
    "        color = get_color_for_category(row['category'])\n",
    "        \n",
    "    statuscode = row['primary_statuscode']\n",
    "    return f\"DE:{statuscode}:{color}\"\n",
    "\n",
    "# sort by category priority. Later statuscodes override earlier ones, so ascending. Then compute animationcodes\n",
    "primary_category_animationcodes = pd.DataFrame(data={'animationcode': df_trip_statuses.sort_values(by=['category_priority']).apply(compute_primary_animationcodes, axis=1, args=('category',))})\n",
    "\n",
    "# sort by delay. Later statuscodes override earlier ones, so ascending. Then compute animationcodes\n",
    "primary_delay_animationcodes = pd.DataFrame(data={'animationcode': df_trip_statuses.sort_values(by=['delay']).apply(compute_primary_animationcodes, axis=1, args=('delay',))})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "c2a16222",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_category_animationcodes.to_csv('de_category_animationcodes.csv', index=False)\n",
    "primary_delay_animationcodes.to_csv('de_delay_animationcodes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a22e128",
   "metadata": {},
   "source": [
    "### Focus animationscodes\n",
    "\n",
    "if the focus signature train is running, pick it. Do that until either all focus signatures have been looked up or a maximum of 4 focus trips is reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e68870e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_hex_color(hex_color, factor):\n",
    "    # HEX -> RGB\n",
    "    r = int(hex_color[0:2], 16)\n",
    "    g = int(hex_color[2:4], 16)\n",
    "    b = int(hex_color[4:6], 16)\n",
    "\n",
    "    # Dimmen und sicherstellen, dass der Wert im Bereich [0, 255] bleibt\n",
    "    r = int(max(0, min(255, r * factor)))\n",
    "    g = int(max(0, min(255, g * factor)))\n",
    "    b = int(max(0, min(255, b * factor)))\n",
    "\n",
    "    # RGB -> HEX\n",
    "    return \"{:02X}{:02X}{:02X}\".format(r, g, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "21c7485d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de_focus_animationcodes_0.csv wurde gelöscht.\n",
      "de_focus_animationcodes_1.csv wurde gelöscht.\n",
      "de_focus_animationcodes_2.csv wurde gelöscht.\n",
      "de_focus_animationcodes_3.csv existiert nicht.\n",
      "                   trip_id       stretch_id                       stretch_name\n",
      "1393  -1151057268452720658  8002553>8002548  Hamburg-Altona -> Hamburg Dammtor\n",
      "1394  -1151057268452720658  8002548>8002549     Hamburg Dammtor -> Hamburg Hbf\n",
      "1395  -1151057268452720658  8002549>8000147     Hamburg Hbf -> Hamburg-Harburg\n",
      "1396  -1151057268452720658  8000147>8000238        Hamburg-Harburg -> Lüneburg\n",
      "1397  -1151057268452720658  8000238>8000168                 Lüneburg -> Uelzen\n",
      "1398  -1151057268452720658  8000168>8000064                    Uelzen -> Celle\n",
      "1399  -1151057268452720658  8000064>8000152              Celle -> Hannover Hbf\n",
      "1400  -1151057268452720658  8000152>8000128          Hannover Hbf -> Göttingen\n",
      "1401  -1151057268452720658  8000128>8003200   Göttingen -> Kassel-Wilhelmshöhe\n",
      "1402  -1151057268452720658  8003200>8000115       Kassel-Wilhelmshöhe -> Fulda\n",
      "1403  -1151057268452720658  8000115>8000260              Fulda -> Würzburg Hbf\n",
      "1404  -1151057268452720658  8000260>8000284       Würzburg Hbf -> Nürnberg Hbf\n",
      "1405  -1151057268452720658  8000183>8000284     Ingolstadt Hbf -> Nürnberg Hbf\n",
      "1406  -1151057268452720658  8000261>8000183      München Hbf -> Ingolstadt Hbf\n",
      "1407  -1151057268452720658  8004158>8000261      München-Pasing -> München Hbf\n",
      "1408  -1151057268452720658  8000013>8004158     Augsburg Hbf -> München-Pasing\n",
      "1409  -1151057268452720658  8000013>8004158     Augsburg Hbf -> München-Pasing\n",
      "1410  -1151057268452720658  8004158>8000261      München-Pasing -> München Hbf\n",
      "                   trip_id       stretch_id                       stretch_name\n",
      "1209  -2467281444360141068  8002553>8002548  Hamburg-Altona -> Hamburg Dammtor\n",
      "1210  -2467281444360141068  8002548>8002549     Hamburg Dammtor -> Hamburg Hbf\n",
      "1211  -2467281444360141068  8002549>8000147     Hamburg Hbf -> Hamburg-Harburg\n",
      "1212  -2467281444360141068  8000147>8000238        Hamburg-Harburg -> Lüneburg\n",
      "1213  -2467281444360141068  8000238>8000168                 Lüneburg -> Uelzen\n",
      "1214  -2467281444360141068  8000168>8010334              Uelzen -> Stendal Hbf\n",
      "1215  -2467281444360141068  8010404>8010334      Berlin-Spandau -> Stendal Hbf\n",
      "1216  -2467281444360141068  8011160>8010404       Berlin Hbf -> Berlin-Spandau\n",
      "1217  -2467281444360141068  8011113>8011160      Berlin Südkreuz -> Berlin Hbf\n",
      "1218  -2467281444360141068  8010050>8011113      Bitterfeld -> Berlin Südkreuz\n",
      "1219  -2467281444360141068  8010205>8010050          Leipzig Hbf -> Bitterfeld\n",
      "1220  -2467281444360141068  8010101>8010205          Erfurt Hbf -> Leipzig Hbf\n",
      "1221  -2467281444360141068  8089478>8010101              Bamberg -> Erfurt Hbf\n",
      "1222  -2467281444360141068  8000284>8089478            Nürnberg Hbf -> Bamberg\n",
      "1223  -2467281444360141068  8000183>8000284     Ingolstadt Hbf -> Nürnberg Hbf\n",
      "1224  -2467281444360141068  8000261>8000183      München Hbf -> Ingolstadt Hbf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "df_focus_signatures = pd.read_csv(FOCUS_SIGNATURES_PATH, dtype=str).dropna(how='all')\n",
    "df_tripid_stretchid = pd.read_csv(TRIPID_STRETCHID_PATH, dtype=str).dropna(how='all')\n",
    "\n",
    "focus_trips_found = 0\n",
    "\n",
    "# remove all old focus trips, in case there were 4 found and now only 3, so that the fourth one doesnt go stale\n",
    "\n",
    "for i in range(4):\n",
    "    filename = f\"de_focus_animationcodes_{i}.csv\"\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "        print(f\"{filename} wurde gelöscht.\")\n",
    "    else:\n",
    "        print(f\"{filename} existiert nicht.\")\n",
    "\n",
    "\n",
    "\n",
    "for index, focus_signature_row in df_focus_signatures.iterrows():\n",
    "    \n",
    "    if focus_trips_found >= 4:\n",
    "        break\n",
    "    \n",
    "    category = focus_signature_row['category']\n",
    "    number = focus_signature_row['number']\n",
    "    \n",
    "    \n",
    "    focus_trip_candidate = df_trip_statuses[(df_trip_statuses['category'] == category) & (df_trip_statuses['number'] == number)]\n",
    "    \n",
    "    if len(focus_trip_candidate) == 0:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    \n",
    "    focus_trip = focus_trip_candidate.iloc[0]\n",
    "    \n",
    "    color_position = get_color_for_category(focus_trip['category'])\n",
    "    color_way_highlighting = dim_hex_color(color_position, 0.4)\n",
    "    \n",
    "    focus_animationcodes = pd.DataFrame(columns=['animationcode'])\n",
    "    \n",
    "    stretchids_for_this_trip = df_tripid_stretchid[df_tripid_stretchid['trip_id'] == focus_trip['trip_id']]\n",
    "    \n",
    "    print(stretchids_for_this_trip)\n",
    "    \n",
    "    stretch_segments_for_this_trip = pd.merge(right=stretchids_for_this_trip, left=stretch_segments, on=['stretch_id'])\n",
    "    \n",
    "    stretch_segments_for_this_trip['primary_statuscode'] = stretch_segments_for_this_trip.apply(lambda row: f\"{row['stretch_id']}_{row['segment_number']}\", axis=1)\n",
    "    focus_animationcodes['animationcode'] = stretch_segments_for_this_trip['primary_statuscode'].map(lambda statuscode: f\"DE:{statuscode}:{color_way_highlighting}\")\n",
    "\n",
    "    position_animationcode_row = pd.DataFrame({'animationcode': [f\"{focus_trip['primary_statuscode']}_{color_position}\"]})\n",
    "    focus_animationcodes = pd.concat([focus_animationcodes, position_animationcode_row])\n",
    "    \n",
    "    focus_animationcodes.to_csv(f'./de_focus_animationcodes_{focus_trips_found}.csv', index=False)\n",
    "    focus_trips_found += 1 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
