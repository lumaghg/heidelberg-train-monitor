{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99c91e9e",
   "metadata": {},
   "source": [
    "# Compute Statuscodes\n",
    "1. check where each train is at the moment\n",
    "2. collect trip ids of trains that are somewhere on the map right now\n",
    "3. check between which stations each trip is\n",
    "4. find the stretch each trip is on\n",
    "5. calculate the position of each train on their respective stretch\n",
    "6. lookup the stretch segment each stretch is on\n",
    "7. put the statuscode together and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "75b146c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250810\n",
      "2508101222\n",
      "2025-08-10\n",
      "2025-08-10 12:22:00\n",
      "('250810', '12')\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from dotenv import load_dotenv\n",
    "from os import getenv\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "STOPTIMES_PATH = 'stoptimes.csv'\n",
    "STRETCHES_PATH = './static/stretches.csv'\n",
    "STRETCH_SEGMENTS_PATH = './static/stretch_segments.csv'\n",
    "STATIONS_PATH = './static/stations.csv'\n",
    "\n",
    "# chatgpt generiert lol\n",
    "import datetime\n",
    "def dateToDBDate(date: datetime.date) -> str:\n",
    "    \"\"\"\n",
    "    Wandelt ein datetime.date Objekt in einen DB-Date-String \"YYMMDD\" um.\n",
    "    \"\"\"\n",
    "    return date.strftime(\"%y%m%d\")\n",
    "\n",
    "\n",
    "def datetimeToDBDatetime(dt: datetime.datetime) -> str:\n",
    "    \"\"\"\n",
    "    Wandelt ein datetime.datetime Objekt in einen DB-Datetime-String \"YYMMDDHHMM\" um.\n",
    "    \"\"\"\n",
    "    return dt.strftime(\"%y%m%d%H%M\")\n",
    "\n",
    "\n",
    "def DBDatetimeToDatetime(dbDate: str) -> datetime.datetime:\n",
    "    \"\"\"\n",
    "    Wandelt einen DB-Datetime-String \"YYMMDDHHMM\" in ein datetime.datetime Objekt um.\n",
    "    \"\"\"\n",
    "    return datetime.datetime.strptime(dbDate, \"%y%m%d%H%M\")\n",
    "\n",
    "\n",
    "def DBDateToDate(dbDate: str) -> datetime.date:\n",
    "    \"\"\"\n",
    "    Wandelt einen DB-Date-String \"YYMMDD\" in ein datetime.date Objekt um.\n",
    "    \"\"\"\n",
    "    return datetime.datetime.strptime(dbDate, \"%y%m%d\").date()\n",
    "\n",
    "def datetimeToDBDateAndHourTuple(dt: datetime.datetime):\n",
    "    date = dt.strftime(\"%y%m%d\")\n",
    "    hour = dt.strftime(\"%H\")\n",
    "    return (date, hour)\n",
    "    \n",
    "       \n",
    "print(dateToDBDate(datetime.date(2025, 8, 10)))\n",
    "print(datetimeToDBDatetime(datetime.datetime(2025, 8, 10, 12, 22)))\n",
    "print(DBDateToDate(\"250810\"))\n",
    "print(DBDatetimeToDatetime(\"2508101222\"))\n",
    "print(datetimeToDBDateAndHourTuple(datetime.datetime(2025, 8, 10, 12, 22)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "06a0a8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stoptimes = pd.read_csv(STOPTIMES_PATH, dtype=\"string\", parse_dates=['arrival', \"departure\"]).dropna(how='all')\n",
    "\n",
    "# remove request_timestamp and request_uic because they were only needed in the df_stoptimes.csv for the preprocessing\n",
    "# to identify outdated and cached data and during change application to match the changes to the stoptime entries.\n",
    "# But they are not needed anymore and as the stoptimes.csv is only read but not overwritten in this script, they can go\n",
    "df_stoptimes = df_stoptimes.drop(labels=['request_timestamp'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3afddccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 14 active trips\n"
     ]
    }
   ],
   "source": [
    "# find active trip ids\n",
    "\n",
    "current_datetime = datetime.datetime.now()\n",
    "    \n",
    "# train is departed, when the departure time was before now\n",
    "df_stoptimes['has_departed_station'] = df_stoptimes['departure'] < current_datetime\n",
    "\n",
    "# find tripids with one stop time and remove them, as for identifying a position on a stretch at least two stops are needed.\n",
    "tripids_with_one_stoptime_mask = df_stoptimes.groupby(\"trip_id\")[\"trip_id\"].transform(\"count\") == 1\n",
    "df_stoptimes = df_stoptimes.drop(df_stoptimes[tripids_with_one_stoptime_mask].index)\n",
    "\n",
    "# find tripids where all stops have been departed and remove them, as that means the trip has ended\n",
    "tripids_ended_mask = df_stoptimes.groupby(\"trip_id\")[\"has_departed_station\"].transform(\"all\")\n",
    "df_stoptimes = df_stoptimes.drop(df_stoptimes[tripids_ended_mask].index)\n",
    "\n",
    "# find tripids where not any stops have been departed and remove them, as that means the trip has not started yet\n",
    "tripids_not_started_mask = ~df_stoptimes.groupby(\"trip_id\")[\"has_departed_station\"].transform(\"any\")\n",
    "df_stoptimes = df_stoptimes.drop(df_stoptimes[tripids_not_started_mask].index)\n",
    "\n",
    "# only the active trips remain\n",
    "\n",
    "no_active_trips = df_stoptimes['trip_id'].unique().shape[0]\n",
    "print(f\"found {no_active_trips} active trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "455fb184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the two stations, between which each train is traveling (standing at a station until departure counts to being between the two stations. \n",
    "# The stopping time animation is handled by calculating where the train is between the two stations and \n",
    "# standing at the second station simply gets mapped to having travelled 100% of the time)\n",
    "# therefore the previous station is the last of the departed stations and the next station is the first of the undeparted stations\n",
    "\n",
    "previous_stations = df_stoptimes[df_stoptimes['has_departed_station'] == True].groupby(by=['trip_id'], as_index=False).last()\n",
    "next_stations = df_stoptimes[df_stoptimes['has_departed_station'] == False].groupby(by=['trip_id'], as_index=False).first()\n",
    "\n",
    "# has_departed_station now not needed anymore\n",
    "previous_stations = previous_stations.drop(labels=['has_departed_station'], axis=1)\n",
    "next_stations = next_stations.drop(labels=['has_departed_station'], axis=1)\n",
    "\n",
    "df_trip_statuses = pd.merge(how='inner', left=previous_stations, right=next_stations, on=['trip_id', 'category', 'number'], suffixes=(\"_previous\", \"_next\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "244fe194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load graph representation of network\n",
    "# station -> nodes\n",
    "# stretches -> edges\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "stretches = pd.read_csv(STRETCHES_PATH, dtype=str).dropna(how='all')\n",
    "stations = pd.read_csv(STATIONS_PATH, dtype=str).dropna(how='all')\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "# add nodes\n",
    "station_list = list(stations.itertuples(index=False, name=None)) # [(station_name, station_uic)]\n",
    "nodes = [(station[1], {'station_name': station[0]}) for station in station_list]\n",
    "G.add_nodes_from(nodes)\n",
    "\n",
    "# add edges\n",
    "# attraction force is used to draw the graph by defining the attraction force between the two nodes and is the inverted travel time\n",
    "edge_list = list(stretches[['station_uic_from', 'station_uic_to', 'station_name_from','station_name_to','travel_cost','super_name']].itertuples(index=False, name=None)) # [(station_name_from, station_uic_from, station_name_to, station_uic_from, travel_cost, super_name)]\n",
    "edges = [(edge[0], edge[1], {'station_name_from': edge[2], 'station_name_to': edge[3], 'travel_cost': int(edge[4]), 'super_name': edge[5], 'attraction_force': 1 / int(edge[4])}) for edge in edge_list]\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2ecf0366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate where the train is\n",
    "import numpy as np\n",
    "\n",
    "# calculate path between the stations, the trip is currently travelling\n",
    "def compute_position_on_graph(row):\n",
    "    previous_station = row['station_uic_previous']\n",
    "    next_station = row['station_uic_next']\n",
    "    previous_station_departure:datetime.datetime = row['departure_previous']\n",
    "    next_station_arrival:datetime.datetime = row['arrival_next']\n",
    "    \n",
    "    shortest_path = nx.shortest_path(G, previous_station, next_station, weight='travel_cost')\n",
    "    \n",
    "    # calculate total travel cost for shortest path\n",
    "    edges = []\n",
    "    total_travel_cost = 0.0\n",
    "    for u, v in zip(shortest_path[:-1], shortest_path[1:]):\n",
    "        travel_cost = int(G[u][v]['travel_cost'])\n",
    "        total_travel_cost += travel_cost\n",
    "        edges.append([u,v,travel_cost])\n",
    "    \n",
    "    # calculate relative travel cost for edge relative to the total cost of the whole path\n",
    "    edges = np.array(edges, dtype=str)\n",
    "    relative_travel_costs = [int(edge[2]) / total_travel_cost for edge in edges]\n",
    "\n",
    "    # cumulative travel costs add up to one, as they were normalized before in relation to total travel cost.\n",
    "    # therefore, the cumulative_relative_travel_costs map to how much progress a trip needs to make on the shortest path to finish a edge of the path.\n",
    "    cumulative_relative_travel_costs = np.cumsum(relative_travel_costs)\n",
    "    \n",
    "    # calculate trip progress on the shortest path\n",
    "    current_time = datetime.datetime.now()\n",
    "    time_elapsed_since_last_stop = current_time - previous_station_departure\n",
    "    trip_travel_time = next_station_arrival - previous_station_departure\n",
    "    trip_progress = time_elapsed_since_last_stop.total_seconds() / trip_travel_time.total_seconds()\n",
    "    \n",
    "    # find the first edge that has not been finished which is the edge currently travelled on\n",
    "    # done by calculating binary array, which returns false for finished (progress < cumcost) and true for finished (progress > cumcost) segments.\n",
    "    # argmax returns the first occurence of the maximum value and 0 in case of no maximum value which is convenient, as the 0th edge is being travelled if\n",
    "    # none are finished and therefore the operation returns in a list full of False \n",
    "    index_of_current_edge = np.argmax(trip_progress < cumulative_relative_travel_costs)\n",
    "    \n",
    "    # with the index, the current edge can be retrieved from the edges\n",
    "    current_edge = edges[index_of_current_edge]\n",
    "    \n",
    "    # to calculate the relative progress on the current edge, the total progress - the relative cost of all finished edges will be divided by the relative cost of the current edge \n",
    "    current_edge_relative_travel_cost = relative_travel_costs[index_of_current_edge]\n",
    "    current_edge_progress_upper_bound = cumulative_relative_travel_costs[index_of_current_edge]\n",
    "    current_edge_progress_lower_bound = current_edge_progress_upper_bound - current_edge_relative_travel_cost\n",
    "    \n",
    "    progress_on_current_edge = (trip_progress - current_edge_progress_lower_bound) / current_edge_relative_travel_cost\n",
    "    \n",
    "    # if the train is standing in the station, progress will show more than 100%, because the time since last departure is longer than \n",
    "    # the time between last departure and next arrival\n",
    "    percentage_on_current_edge = min(int(progress_on_current_edge * 100), 100)\n",
    "    \n",
    "    station_uic_from = current_edge[0]\n",
    "    station_uic_to = current_edge[1]\n",
    "    # find id of current edge in stretches\n",
    "    \n",
    "    travels_in_reverse_direction = False\n",
    "    \n",
    "    current_stretch = stretches[(stretches['station_uic_from'] == station_uic_from) & (stretches['station_uic_to'] == station_uic_to)]\n",
    "    \n",
    "    # stretches are defined one way but work both ways\n",
    "    if len(current_stretch) == 0:\n",
    "        current_stretch = stretches[(stretches['station_uic_to'] == station_uic_from) & (stretches['station_uic_from'] == station_uic_to)]\n",
    "        travels_in_reverse_direction = True\n",
    "    \n",
    "    if len(current_stretch) == 0:\n",
    "        print(f'No Stretch found for edge: {current_edge}')\n",
    "        \n",
    "    current_stretch_id = current_stretch.iloc[0]['stretch_id']\n",
    "    current_stretch_name = current_stretch.iloc[0]['stretch_name']\n",
    "    current_stretch_super_name = current_stretch.iloc[0]['super_name']\n",
    "    \n",
    "    return {'stretch_super_name': current_stretch_super_name,'stretch_name': current_stretch_name,'progress': percentage_on_current_edge, 'stretch_id': current_stretch_id,  'travelling_reverse': travels_in_reverse_direction}\n",
    "    \n",
    "df_trip_statuses['position'] = df_trip_statuses.apply(compute_position_on_graph, axis=1) \n",
    "\n",
    "# arrival and departure times and stations are no longer needed\n",
    "\n",
    "#df_trip_statuses = df_trip_statuses.drop(['station_name_previous','station_uic_previous','arrival_previous','departure_previous','station_name_next','station_uic_next','arrival_next','departure_next'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f12fb151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup row in stretch_id + % to stretch_segment / LED mapping\n",
    "from collections import defaultdict\n",
    "\n",
    "types = defaultdict(lambda: str, lower_bound = \"int\", upper_bound = \"int\")\n",
    "stretch_segments = pd.read_csv(STRETCH_SEGMENTS_PATH, dtype=types).dropna(how='all')\n",
    "\n",
    "# find rows where the progress of the trip fits, can be 1 or 2 if the progress is right on the edge because of both sides inclusive\n",
    "def compute_primary_statuscode(row):\n",
    "    position = row['position']\n",
    "    stretch_id = position['stretch_id']\n",
    "    progress = int(position['progress'])\n",
    "    is_travelling_reverse = position['travelling_reverse']\n",
    "    \n",
    "    # if the train is travelling in the inverse direction, the progress needs to be inverted. Hamburg -> Hannover 20% and Hannover -> Hamburg 80% are the same positions\n",
    "    stretch_position = (100 - progress) if is_travelling_reverse else progress\n",
    "    \n",
    "    # find stretch segments that fit and take the first one, as it is right on the edge between two segments if there are more than one\n",
    "    stretch_id_mask = stretch_segments['stretch_id'] == stretch_id\n",
    "    lower_bound_mask = stretch_segments['lower_bound'] <= stretch_position\n",
    "    upper_bound_mask = stretch_position <= stretch_segments['upper_bound']\n",
    "    \n",
    "    applicable_segments = stretch_segments[stretch_id_mask & lower_bound_mask & upper_bound_mask]\n",
    "    \n",
    "    segment = None\n",
    "    if len(applicable_segments) < 1:\n",
    "        return\n",
    "    else:\n",
    "        segment = applicable_segments.iloc[0]\n",
    "    \n",
    "    statuscode = f\"{segment['stretch_id']}_{segment['segment_number']}\"\n",
    "    \n",
    "    return statuscode\n",
    "\n",
    "# optionally compute statuscode for secondary LED by building list of all segment rows along the path, then group by LED and find the LED before the current one.\n",
    "\n",
    "df_trip_statuses['primary_statuscode'] = df_trip_statuses.apply(compute_primary_statuscode, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "49a93f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute delay\n",
    "# choose arrival_delay_next if the train has not reached the next station, choose departure_delay_next if the train has reached the next station\n",
    "\n",
    "def compute_delay(row):\n",
    "    arrival_next = row['arrival_next']\n",
    "    \n",
    "    # train is still travelling    \n",
    "    if arrival_next > datetime.datetime.now():\n",
    "        return row['arrival_delay_next']\n",
    "    \n",
    "    # train has reached next station\n",
    "    else:\n",
    "        return row['departure_delay_next']     \n",
    "    \n",
    "df_trip_statuses['delay'] = df_trip_statuses.apply(compute_delay, axis=1)\n",
    "\n",
    "# if the memory is needed, drop the old delay columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9f9aeca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# color mapping for animationcodes\n",
    "\n",
    "def get_color_for_category(category: str):\n",
    "    if category in ['IC', 'EC']:\n",
    "        return \"00FFFF\"\n",
    "    \n",
    "    if category in ['ICE']:\n",
    "        return \"FFFFFF\"\n",
    "    \n",
    "    if category in ['FLX','WB']:\n",
    "        return \"00FF00\"\n",
    "    \n",
    "    if category in ['RJ', 'RJX', 'ECE']:\n",
    "        return \"FFAA00\"\n",
    "    \n",
    "    if category in ['EST','TGV']:\n",
    "        return \"FF0000\"\n",
    "    \n",
    "    if category in ['NJ','EN','ES','DN','D','SJ']:\n",
    "        return \"CC00FF\"\n",
    "    \n",
    "    return \"FFFF00\"\n",
    "\n",
    "def get_color_for_delay(delay: str):\n",
    "    delay = int(delay)\n",
    "    \n",
    "    if delay > 60:\n",
    "        return \"FF0000\"\n",
    "    if delay > 30:\n",
    "        return \"FF8800\"\n",
    "    if delay > 10:\n",
    "        return \"FFFF00\"\n",
    "    else:\n",
    "        return \"00FF00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7273056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build animationcodes\n",
    "\n",
    "def compute_primary_animationcodes(row, color_by: str):\n",
    "    if color_by == 'delay':\n",
    "        color = get_color_for_delay(row['delay'])\n",
    "    else:\n",
    "        color = get_color_for_category(row['category'])\n",
    "        \n",
    "    statuscode = row['primary_statuscode']\n",
    "    return f\"DE:{statuscode}:{color}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "244b4ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_category_animationcodes = pd.DataFrame(data={'animationcodes': df_trip_statuses.apply(compute_primary_animationcodes, axis=1, args=('category',))})\n",
    "primary_delay_animationcodes = pd.DataFrame(data={'animationcodes': df_trip_statuses.apply(compute_primary_animationcodes, axis=1, args=('delay',))})\n",
    "\n",
    "\n",
    "primary_category_animationcodes.to_csv('de_category_animationcodes.csv')\n",
    "primary_delay_animationcodes.to_csv('de_delay_animationcodes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c7485d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
