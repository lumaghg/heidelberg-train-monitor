{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cbcec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dotenv import load_dotenv\n",
    "from os import getenv\n",
    "import pandas as pd\n",
    "import ratelimit\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "STOPTIMES_PATH = 'stoptimes.csv'\n",
    "PLANNED_STOPTIMES_PATH = 'stoptimes_planned.csv'\n",
    "STATIONS_PATH = './static/stations.csv'\n",
    "\n",
    "FV_CATEGORIES = [\"IC\", \"EC\", \"ICE\", \"FLX\", \"WB\", \"RJ\", \"RJX\", \"ECE\", \"EST\", \"TGV\", \"NJ\", \"EN\", \"ES\", \"DN\", \"D\", \"SJ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23474ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250810\n",
      "2508101222\n",
      "2025-08-10\n",
      "2025-08-10 12:22:00\n",
      "('250810', '12')\n"
     ]
    }
   ],
   "source": [
    "# chatgpt generiert lol\n",
    "import datetime\n",
    "def dateToDBDate(date: datetime.date) -> str:\n",
    "    \"\"\"\n",
    "    Wandelt ein datetime.date Objekt in einen DB-Date-String \"YYMMDD\" um.\n",
    "    \"\"\"\n",
    "    return date.strftime(\"%y%m%d\")\n",
    "\n",
    "\n",
    "def datetimeToDBDatetime(dt: datetime.datetime) -> str:\n",
    "    \"\"\"\n",
    "    Wandelt ein datetime.datetime Objekt in einen DB-Datetime-String \"YYMMDDHHMM\" um.\n",
    "    \"\"\"\n",
    "    return dt.strftime(\"%y%m%d%H%M\")\n",
    "\n",
    "\n",
    "def DBDatetimeToDatetime(dbDate: str) -> datetime.datetime:\n",
    "    \"\"\"\n",
    "    Wandelt einen DB-Datetime-String \"YYMMDDHHMM\" in ein datetime.datetime Objekt um.\n",
    "    \"\"\"\n",
    "    return datetime.datetime.strptime(dbDate, \"%y%m%d%H%M\")\n",
    "\n",
    "\n",
    "def DBDateToDate(dbDate: str) -> datetime.date:\n",
    "    \"\"\"\n",
    "    Wandelt einen DB-Date-String \"YYMMDD\" in ein datetime.date Objekt um.\n",
    "    \"\"\"\n",
    "    return datetime.datetime.strptime(dbDate, \"%y%m%d\").date()\n",
    "\n",
    "def datetimeToDBDateAndHourTuple(dt: datetime.datetime):\n",
    "    date = dt.strftime(\"%y%m%d\")\n",
    "    hour = dt.strftime(\"%H\")\n",
    "    return (date, hour)\n",
    "    \n",
    "       \n",
    "print(dateToDBDate(datetime.date(2025, 8, 10)))\n",
    "print(datetimeToDBDatetime(datetime.datetime(2025, 8, 10, 12, 22)))\n",
    "print(DBDateToDate(\"250810\"))\n",
    "print(DBDatetimeToDatetime(\"2508101222\"))\n",
    "print(datetimeToDBDateAndHourTuple(datetime.datetime(2025, 8, 10, 12, 22)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "009ee455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          station_name station_uic\n",
      "0        Dagebüll Mole     8007769\n",
      "1     Westerland(Sylt)     8006369\n",
      "2              Niebüll     8004343\n",
      "3                Husum     8000181\n",
      "4         Heide(Holst)     8000155\n",
      "..                 ...         ...\n",
      "94  Kaiserslautern Hbf     8000189\n",
      "95     Saarbrücken Hbf     8000323\n",
      "96          Metz Ville     8700019\n",
      "97          Strasbourg     8700023\n",
      "98           Paris Est     8700011\n",
      "\n",
      "[99 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# load stations that need to be requested\n",
    "df_stations = pd.read_csv(STATIONS_PATH, dtype=str).dropna(how='all')\n",
    "print(df_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "471bbedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def extract_tripid_from_stopid(stop_id: str):\n",
    "                \n",
    "    has_dash = True if stop_id.startswith(\"-\") else False\n",
    "\n",
    "    trip_id = None\n",
    "\n",
    "    if has_dash:\n",
    "        # if stop id has dash, the first split result will be empty\n",
    "        trip_id = stop_id.split(\"-\")[1]\n",
    "        trip_id = f\"-{trip_id}\"\n",
    "    else:\n",
    "        trip_id = stop_id.split(\"-\")[0]\n",
    "    return trip_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b750e95f",
   "metadata": {},
   "source": [
    "Fall 1: id ist bekannt\n",
    "    Fall 1.1: id/uic Kombination ist bekannt: update / canceled => wenn cs = c dann auf None, sonst auf ct setzen\n",
    "    Fall 1.2: id/uic Kombination ist nicht bekannt: neuer stop, category und number klauen, neu anlegen mit time, evtl. erstmal ignorieren bis solche Daten da sind\n",
    "    Schluss\n",
    "Fall 2: id ist nicht bekannt => neuer Trip. Trip hat planned data und trip label, neuen stop anlegen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34dfa44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching fchg for Dagebüll Mole\n",
      "skipping date: 2025-09-15 09:30:00\n",
      "skipping date: 2025-09-15 12:56:00\n",
      "fetching fchg for Westerland(Sylt)\n",
      "skipping date: 2025-09-15 10:57:00\n",
      "skipping date: 2025-09-15 13:36:00\n",
      "skipping date: 2025-09-15 09:25:00\n",
      "fetching fchg for Niebüll\n",
      "skipping date: 2025-09-15 11:32:00\n",
      "skipping date: 2025-09-15 12:39:00\n",
      "skipping date: 2025-09-15 12:39:00\n",
      "skipping date: 2025-09-15 10:00:00\n",
      "skipping date: 2025-09-15 09:54:00\n",
      "fetching fchg for Husum\n",
      "skipping date: 2025-09-15 12:13:00\n",
      "skipping date: 2025-09-15 10:37:00\n",
      "skipping date: 2025-09-15 10:37:00\n",
      "skipping date: 2025-09-15 11:48:00\n",
      "skipping date: 2025-09-15 11:48:00\n",
      "fetching fchg for Heide(Holst)\n",
      "skipping date: 2025-09-15 12:37:00\n",
      "skipping date: 2025-09-15 11:03:00\n",
      "skipping date: 2025-09-15 11:03:00\n",
      "skipping date: 2025-09-15 11:21:00\n",
      "skipping date: 2025-09-15 11:21:00\n",
      "fetching fchg for Itzehoe\n",
      "skipping date: 2025-09-15 13:21:00\n",
      "skipping date: 2025-09-15 13:54:00\n",
      "skipping date: 2025-09-15 13:54:00\n",
      "skipping date: 2025-09-15 11:48:00\n",
      "skipping date: 2025-09-15 11:48:00\n",
      "skipping date: 2025-09-15 10:32:00\n",
      "skipping date: 2025-09-15 10:32:00\n",
      "fetching fchg for Elmshorn\n",
      "fetching fchg for Hamburg-Altona\n",
      "skipping date: 2025-09-15 11:29:00\n",
      "skipping date: 2025-09-15 12:47:00\n",
      "skipping date: 2025-09-15 12:13:00\n",
      "skipping date: 2025-09-15 11:11:00\n",
      "skipping date: 2025-09-15 13:12:00\n",
      "skipping date: 2025-09-15 11:11:00\n",
      "skipping date: 2025-09-15 07:23:00\n",
      "skipping date: 2025-09-15 13:46:00\n",
      "skipping date: 2025-09-15 13:34:00\n",
      "skipping date: 2025-09-15 12:50:00\n",
      "skipping date: 2025-09-15 12:29:00\n",
      "skipping date: 2025-09-15 12:19:00\n",
      "skipping date: 2025-09-15 07:37:00\n",
      "skipping date: 2025-09-15 07:45:00\n",
      "skipping date: 2025-09-15 10:27:00\n",
      "skipping date: 2025-09-15 08:30:00\n",
      "skipping date: 2025-09-15 12:10:00\n",
      "skipping date: 2025-09-15 11:40:00\n",
      "skipping date: 2025-09-15 09:29:00\n",
      "skipping date: 2025-09-15 07:29:00\n",
      "skipping date: 2025-09-15 09:22:00\n",
      "skipping date: 2025-09-15 13:00:00\n",
      "skipping date: 2025-09-15 11:34:00\n",
      "skipping date: 2025-09-15 10:13:00\n",
      "skipping date: 2025-09-15 08:09:00\n",
      "skipping date: 2025-09-15 07:19:00\n",
      "skipping date: 2025-09-15 10:21:00\n",
      "skipping date: 2025-09-15 06:34:00\n",
      "skipping date: 2025-09-15 12:25:00\n",
      "fetching fchg for Hamburg Dammtor\n",
      "skipping date: 2025-09-15 13:36:00\n",
      "skipping date: 2025-09-15 11:35:00\n",
      "skipping date: 2025-09-16 10:19:00\n",
      "skipping date: 2025-09-15 13:15:00\n",
      "skipping date: 2025-09-15 13:55:00\n",
      "skipping date: 2025-09-15 11:56:00\n",
      "skipping date: 2025-09-15 12:56:00\n",
      "skipping date: 2025-09-15 11:15:00\n",
      "skipping date: 2025-09-15 12:19:00\n",
      "skipping date: 2025-09-15 11:17:00\n",
      "skipping date: 2025-09-15 13:21:00\n",
      "skipping date: 2025-09-15 12:15:00\n",
      "skipping date: 2025-09-15 11:18:00\n",
      "skipping date: 2025-09-17 10:20:00\n",
      "skipping date: 2025-09-15 07:30:00\n",
      "skipping date: 2025-09-15 13:11:00\n",
      "skipping date: 2025-09-15 13:11:00\n",
      "skipping date: 2025-09-15 12:41:00\n",
      "skipping date: 2025-09-15 12:37:00\n",
      "skipping date: 2025-09-15 12:25:00\n",
      "skipping date: 2025-09-15 07:44:00\n",
      "skipping date: 2025-09-15 06:15:00\n",
      "skipping date: 2025-09-15 07:53:00\n",
      "skipping date: 2025-09-15 10:54:00\n",
      "skipping date: 2025-09-15 06:55:00\n",
      "skipping date: 2025-09-15 10:35:00\n",
      "skipping date: 2025-09-15 08:36:00\n",
      "skipping date: 2025-09-15 09:43:00\n",
      "skipping date: 2025-09-15 09:43:00\n",
      "skipping date: 2025-09-15 12:02:00\n",
      "skipping date: 2025-09-15 09:54:00\n",
      "skipping date: 2025-09-15 09:17:00\n",
      "skipping date: 2025-09-15 09:35:00\n",
      "skipping date: 2025-09-15 07:36:00\n",
      "skipping date: 2025-09-15 10:22:00\n",
      "skipping date: 2025-09-15 08:16:00\n",
      "skipping date: 2025-09-15 07:25:00\n",
      "skipping date: 2025-09-15 11:54:00\n",
      "skipping date: 2025-09-15 08:50:00\n",
      "fetching fchg for Hamburg Hbf\n",
      "skipping date: 2025-09-17 10:14:00\n",
      "skipping date: 2025-09-15 12:49:00\n",
      "skipping date: 2025-09-15 06:18:00\n",
      "skipping date: 2025-09-15 12:47:00\n",
      "skipping date: 2025-09-15 06:44:00\n",
      "skipping date: 2025-09-15 00:41:00\n",
      "fetching fchg for Hamburg-Harburg\n",
      "skipping date: 2025-09-17 10:01:00\n",
      "skipping date: 2025-09-15 06:31:00\n",
      "fetching fchg for Lüneburg\n",
      "skipping date: 2025-09-15 06:47:00\n",
      "fetching fchg for Uelzen\n",
      "skipping date: 2025-09-15 12:06:00\n",
      "skipping date: 2025-09-15 12:08:00\n",
      "fetching fchg for Celle\n",
      "fetching fchg for Hannover Hbf\n",
      "skipping date: 2025-09-15 11:13:00\n",
      "skipping date: 2025-09-15 13:36:00\n",
      "fetching fchg for Göttingen\n",
      "skipping date: 2025-09-15 13:34:00\n",
      "skipping date: 2025-09-15 13:00:00\n",
      "skipping date: 2025-09-15 12:56:00\n",
      "skipping date: 2025-09-15 12:56:00\n",
      "skipping date: 2025-09-15 10:04:00\n",
      "skipping date: 2025-09-15 13:08:00\n",
      "skipping date: 2025-09-15 12:37:00\n",
      "skipping date: 2025-09-15 12:26:00\n",
      "skipping date: 2025-09-15 10:43:00\n",
      "skipping date: 2025-09-15 08:20:00\n",
      "skipping date: 2025-09-15 10:07:00\n",
      "skipping date: 2025-09-15 11:43:00\n",
      "skipping date: 2025-09-15 11:05:00\n",
      "skipping date: 2025-09-15 09:06:00\n",
      "skipping date: 2025-09-15 12:00:00\n",
      "skipping date: 2025-09-15 11:59:00\n",
      "skipping date: 2025-09-15 11:15:00\n",
      "skipping date: 2025-09-15 11:33:00\n",
      "skipping date: 2025-09-15 10:35:00\n",
      "skipping date: 2025-09-15 09:41:00\n",
      "skipping date: 2025-09-15 11:02:00\n",
      "skipping date: 2025-09-15 07:41:00\n",
      "fetching fchg for Kassel-Wilhelmshöhe\n",
      "skipping date: 2025-09-15 13:38:00\n",
      "skipping date: 2025-09-15 13:10:00\n",
      "skipping date: 2025-09-15 12:39:00\n",
      "skipping date: 2025-09-15 12:31:00\n",
      "skipping date: 2025-09-15 12:32:00\n",
      "skipping date: 2025-09-15 13:34:00\n",
      "skipping date: 2025-09-15 10:28:00\n",
      "skipping date: 2025-09-15 13:34:00\n",
      "skipping date: 2025-09-15 13:02:00\n",
      "skipping date: 2025-09-15 12:22:00\n",
      "skipping date: 2025-09-15 10:20:00\n",
      "skipping date: 2025-09-15 08:41:00\n",
      "skipping date: 2025-09-15 10:33:00\n",
      "skipping date: 2025-09-15 11:22:00\n",
      "skipping date: 2025-09-15 11:26:00\n",
      "skipping date: 2025-09-15 09:29:00\n",
      "skipping date: 2025-09-15 11:40:00\n",
      "skipping date: 2025-09-15 11:36:00\n",
      "skipping date: 2025-09-15 11:12:00\n",
      "skipping date: 2025-09-15 12:05:00\n",
      "skipping date: 2025-09-15 10:58:00\n",
      "skipping date: 2025-09-15 09:17:00\n",
      "skipping date: 2025-09-15 10:40:00\n",
      "skipping date: 2025-09-15 08:01:00\n",
      "skipping date: 2025-09-15 06:22:00\n",
      "skipping date: 2025-09-15 06:22:00\n",
      "fetching fchg for Fulda\n",
      "skipping date: 2025-09-15 12:36:00\n",
      "skipping date: 2025-09-15 13:25:00\n",
      "skipping date: 2025-09-15 12:00:00\n",
      "skipping date: 2025-09-15 12:01:00\n",
      "skipping date: 2025-09-15 13:40:00\n",
      "skipping date: 2025-09-15 11:14:00\n",
      "skipping date: 2025-09-15 13:03:00\n",
      "skipping date: 2025-09-15 11:10:00\n",
      "skipping date: 2025-09-15 12:10:00\n",
      "skipping date: 2025-09-15 10:03:00\n",
      "skipping date: 2025-09-15 11:14:00\n",
      "skipping date: 2025-09-15 10:59:00\n",
      "skipping date: 2025-09-15 11:23:00\n",
      "skipping date: 2025-09-15 10:06:00\n",
      "skipping date: 2025-09-15 12:11:00\n",
      "skipping date: 2025-09-15 08:28:00\n",
      "fetching fchg for Hanau Hbf\n",
      "skipping date: 2025-09-15 13:51:00\n",
      "skipping date: 2025-09-15 09:10:00\n",
      "skipping date: 2025-09-15 11:12:00\n",
      "skipping date: 2025-09-15 09:08:00\n",
      "fetching fchg for Frankfurt(Main)Süd\n",
      "skipping date: 2025-09-15 12:17:00\n",
      "skipping date: 2025-09-15 09:21:00\n",
      "fetching fchg for Frankfurt(Main)Hbf\n",
      "skipping date: 2025-09-16 04:39:00\n",
      "skipping date: 2025-09-16 01:48:00\n",
      "skipping date: 2025-09-15 06:42:00\n",
      "skipping date: 2025-09-15 12:43:00\n",
      "skipping date: 2025-09-15 12:08:00\n",
      "skipping date: 2025-09-15 13:47:00\n",
      "skipping date: 2025-09-15 10:46:00\n",
      "skipping date: 2025-09-15 11:04:00\n",
      "skipping date: 2025-09-16 10:20:00\n",
      "skipping date: 2025-09-17 04:38:00\n",
      "skipping date: 2025-09-15 13:39:00\n",
      "skipping date: 2025-09-15 13:31:00\n",
      "skipping date: 2025-09-15 13:22:00\n",
      "skipping date: 2025-09-15 13:12:00\n",
      "skipping date: 2025-09-15 13:06:00\n",
      "skipping date: 2025-09-15 13:01:00\n",
      "skipping date: 2025-09-15 08:55:00\n",
      "skipping date: 2025-09-15 10:07:00\n",
      "skipping date: 2025-09-15 09:55:00\n",
      "skipping date: 2025-09-15 09:37:00\n",
      "skipping date: 2025-09-15 09:30:00\n",
      "skipping date: 2025-09-15 07:54:00\n",
      "skipping date: 2025-09-15 12:18:00\n",
      "skipping date: 2025-09-15 10:48:00\n",
      "skipping date: 2025-09-15 10:43:00\n",
      "skipping date: 2025-09-15 09:30:00\n",
      "skipping date: 2025-09-15 09:05:00\n",
      "fetching fchg for Frankfurt(M) Flughafen Fernbf\n",
      "skipping date: 2025-09-16 04:59:00\n",
      "skipping date: 2025-09-15 06:54:00\n",
      "skipping date: 2025-09-15 11:06:00\n",
      "skipping date: 2025-09-15 13:23:00\n",
      "skipping date: 2025-09-15 10:45:00\n",
      "skipping date: 2025-09-17 04:57:00\n",
      "skipping date: 2025-09-15 13:48:00\n",
      "skipping date: 2025-09-15 13:56:00\n",
      "skipping date: 2025-09-15 13:30:00\n",
      "skipping date: 2025-09-15 13:09:00\n",
      "skipping date: 2025-09-15 10:07:00\n",
      "skipping date: 2025-09-15 08:39:00\n",
      "skipping date: 2025-09-15 09:58:00\n",
      "skipping date: 2025-09-15 07:06:00\n",
      "skipping date: 2025-09-15 09:07:00\n",
      "skipping date: 2025-09-15 12:09:00\n",
      "skipping date: 2025-09-15 10:40:00\n",
      "fetching fchg for Mannheim Hbf\n",
      "skipping date: 2025-09-16 03:55:00\n",
      "skipping date: 2025-09-16 01:09:00\n",
      "skipping date: 2025-09-15 08:44:00\n",
      "skipping date: 2025-09-15 10:30:00\n",
      "skipping date: 2025-09-15 11:20:00\n",
      "skipping date: 2025-09-15 13:19:00\n",
      "skipping date: 2025-09-15 12:05:00\n",
      "skipping date: 2025-09-15 10:10:00\n",
      "skipping date: 2025-09-15 13:31:00\n",
      "skipping date: 2025-09-17 03:55:00\n",
      "skipping date: 2025-09-16 20:47:00\n",
      "skipping date: 2025-09-15 13:56:00\n",
      "skipping date: 2025-09-15 13:35:00\n",
      "skipping date: 2025-09-15 12:30:00\n",
      "skipping date: 2025-09-15 09:24:00\n",
      "skipping date: 2025-09-15 08:00:00\n",
      "skipping date: 2025-09-15 10:54:00\n",
      "skipping date: 2025-09-15 09:15:00\n",
      "skipping date: 2025-09-15 07:14:00\n",
      "skipping date: 2025-09-15 11:51:00\n",
      "skipping date: 2025-09-15 06:28:00\n",
      "skipping date: 2025-09-15 08:34:00\n",
      "skipping date: 2025-09-15 11:59:00\n",
      "skipping date: 2025-09-15 11:13:00\n",
      "skipping date: 2025-09-15 10:01:00\n",
      "skipping date: 2025-09-15 10:04:00\n",
      "skipping date: 2025-09-15 09:51:00\n",
      "fetching fchg for Vaihingen(Enz)\n",
      "skipping date: 2025-09-15 07:52:00\n",
      "fetching fchg for Stuttgart Hbf\n",
      "skipping date: 2025-09-16 01:58:00\n",
      "skipping date: 2025-09-16 00:28:00\n",
      "skipping date: 2025-09-16 00:46:00\n",
      "skipping date: 2025-09-15 07:37:00\n",
      "skipping date: 2025-09-15 11:03:00\n",
      "skipping date: 2025-09-15 09:40:00\n",
      "skipping date: 2025-09-15 11:31:00\n",
      "skipping date: 2025-09-15 08:57:00\n",
      "skipping date: 2025-09-15 09:34:00\n",
      "skipping date: 2025-09-16 11:51:00\n",
      "skipping date: 2025-09-17 02:16:00\n",
      "skipping date: 2025-09-16 20:04:00\n",
      "skipping date: 2025-09-15 12:53:00\n",
      "skipping date: 2025-09-15 07:23:00\n",
      "skipping date: 2025-09-15 05:42:00\n",
      "skipping date: 2025-09-15 07:53:00\n",
      "skipping date: 2025-09-15 12:01:00\n",
      "skipping date: 2025-09-15 11:16:00\n",
      "skipping date: 2025-09-15 09:19:00\n",
      "fetching fchg for Esslingen(Neckar)\n",
      "fetching fchg for Ulm Hbf\n",
      "skipping date: 2025-09-16 01:14:00\n",
      "skipping date: 2025-09-15 08:47:00\n",
      "skipping date: 2025-09-17 01:14:00\n",
      "skipping date: 2025-09-15 04:47:00\n",
      "skipping date: 2025-09-15 06:46:00\n",
      "skipping date: 2025-09-15 12:41:00\n",
      "fetching fchg for Augsburg Hbf\n",
      "skipping date: 2025-09-16 01:03:00\n",
      "skipping date: 2025-09-16 00:53:00\n",
      "skipping date: 2025-09-16 00:01:00\n",
      "skipping date: 2025-09-16 14:54:00\n",
      "skipping date: 2025-09-15 07:34:00\n",
      "skipping date: 2025-09-16 14:18:00\n",
      "skipping date: 2025-09-16 23:37:00\n",
      "skipping date: 2025-09-16 00:01:00\n",
      "skipping date: 2025-09-15 12:50:00\n",
      "skipping date: 2025-09-15 12:30:00\n",
      "skipping date: 2025-09-15 12:23:00\n",
      "skipping date: 2025-09-15 07:43:00\n",
      "skipping date: 2025-09-15 08:39:00\n",
      "skipping date: 2025-09-15 03:44:00\n",
      "skipping date: 2025-09-15 05:17:00\n",
      "skipping date: 2025-09-15 08:19:00\n",
      "skipping date: 2025-09-15 10:19:00\n",
      "fetching fchg for München-Pasing\n",
      "skipping date: 2025-09-16 01:24:00\n",
      "skipping date: 2025-09-16 01:14:00\n",
      "skipping date: 2025-09-16 15:18:00\n",
      "skipping date: 2025-09-15 07:11:00\n",
      "skipping date: 2025-09-16 15:18:00\n",
      "skipping date: 2025-09-15 12:27:00\n",
      "skipping date: 2025-09-15 07:20:00\n",
      "skipping date: 2025-09-15 04:53:00\n",
      "skipping date: 2025-09-15 12:03:00\n",
      "skipping date: 2025-09-15 11:57:00\n",
      "skipping date: 2025-09-15 09:54:00\n",
      "skipping date: 2025-09-15 09:44:00\n",
      "skipping date: 2025-09-15 07:54:00\n",
      "[RateLimit] Limit erreicht (58/58s). Warte auf freien Slot...\n",
      "[RateLimit] Slot frei, Request wird gesendet.\n",
      "fetching fchg for München Ost\n",
      "skipping date: 2025-09-15 12:08:00\n",
      "skipping date: 2025-09-15 11:38:00\n",
      "[RateLimit] Limit erreicht (58/58s). Warte auf freien Slot...\n",
      "[RateLimit] Slot frei, Request wird gesendet.\n",
      "fetching fchg for München Hbf\n",
      "skipping date: 2025-09-16 01:31:00\n",
      "skipping date: 2025-09-16 01:21:00\n",
      "skipping date: 2025-09-16 15:25:00\n",
      "skipping date: 2025-09-15 07:03:00\n",
      "skipping date: 2025-09-15 11:17:00\n",
      "skipping date: 2025-09-15 11:17:00\n",
      "skipping date: 2025-09-15 10:19:00\n",
      "skipping date: 2025-09-15 09:17:00\n",
      "skipping date: 2025-09-15 09:17:00\n",
      "skipping date: 2025-09-16 15:25:00\n",
      "skipping date: 2025-09-15 09:54:00\n",
      "skipping date: 2025-09-16 22:44:00\n",
      "skipping date: 2025-09-15 13:55:00\n",
      "skipping date: 2025-09-15 12:57:00\n",
      "skipping date: 2025-09-15 06:57:00\n",
      "skipping date: 2025-09-15 08:17:00\n",
      "skipping date: 2025-09-15 07:13:00\n",
      "skipping date: 2025-09-15 08:54:00\n",
      "skipping date: 2025-09-15 08:14:00\n",
      "skipping date: 2025-09-15 07:17:00\n",
      "skipping date: 2025-09-15 03:16:00\n",
      "skipping date: 2025-09-15 04:46:00\n",
      "skipping date: 2025-09-15 11:52:00\n",
      "skipping date: 2025-09-15 11:30:00\n",
      "skipping date: 2025-09-15 09:47:00\n",
      "skipping date: 2025-09-15 07:47:00\n",
      "fetching fchg for Ingolstadt Hbf\n",
      "skipping date: 2025-09-15 11:57:00\n",
      "skipping date: 2025-09-15 11:57:00\n",
      "skipping date: 2025-09-15 10:57:00\n",
      "skipping date: 2025-09-15 09:57:00\n",
      "skipping date: 2025-09-15 09:57:00\n",
      "skipping date: 2025-09-15 10:32:00\n",
      "skipping date: 2025-09-15 13:21:00\n",
      "skipping date: 2025-09-15 12:13:00\n",
      "skipping date: 2025-09-15 08:57:00\n",
      "skipping date: 2025-09-15 07:55:00\n",
      "fetching fchg for Nürnberg Hbf\n",
      "skipping date: 2025-09-15 12:29:00\n",
      "skipping date: 2025-09-15 12:30:00\n",
      "skipping date: 2025-09-15 11:27:00\n",
      "skipping date: 2025-09-15 10:27:00\n",
      "skipping date: 2025-09-15 10:28:00\n",
      "skipping date: 2025-09-15 11:03:00\n",
      "skipping date: 2025-09-15 13:41:00\n",
      "skipping date: 2025-09-15 13:30:00\n",
      "skipping date: 2025-09-15 12:40:00\n",
      "skipping date: 2025-09-15 12:44:00\n",
      "skipping date: 2025-09-15 13:03:00\n",
      "skipping date: 2025-09-15 12:52:00\n",
      "skipping date: 2025-09-15 08:02:00\n",
      "skipping date: 2025-09-15 11:37:00\n",
      "skipping date: 2025-09-15 07:30:00\n",
      "skipping date: 2025-09-15 09:28:00\n",
      "skipping date: 2025-09-15 09:02:00\n",
      "skipping date: 2025-09-15 10:05:00\n",
      "skipping date: 2025-09-15 08:31:00\n",
      "skipping date: 2025-09-15 03:07:00\n",
      "fetching fchg for Bamberg\n",
      "fetching fchg for Erfurt Hbf\n",
      "skipping date: 2025-09-15 13:23:00\n",
      "skipping date: 2025-09-15 13:30:00\n",
      "skipping date: 2025-09-15 10:51:00\n",
      "skipping date: 2025-09-15 13:25:00\n",
      "skipping date: 2025-09-15 12:42:00\n",
      "skipping date: 2025-09-15 09:25:00\n",
      "skipping date: 2025-09-15 10:26:00\n",
      "skipping date: 2025-09-15 08:34:00\n",
      "skipping date: 2025-09-15 11:23:00\n",
      "skipping date: 2025-09-15 11:23:00\n",
      "skipping date: 2025-09-15 11:26:00\n",
      "skipping date: 2025-09-15 10:48:00\n",
      "skipping date: 2025-09-15 09:29:00\n",
      "fetching fchg for Halle(Saale)Hbf\n",
      "fetching fchg for Bitterfeld\n",
      "skipping date: 2025-09-15 12:36:00\n",
      "skipping date: 2025-09-15 11:21:00\n",
      "skipping date: 2025-09-15 10:35:00\n",
      "fetching fchg for Berlin Südkreuz\n",
      "skipping date: 2025-09-15 13:32:00\n",
      "skipping date: 2025-09-15 13:14:00\n",
      "skipping date: 2025-09-15 11:13:00\n",
      "skipping date: 2025-09-15 13:38:00\n",
      "skipping date: 2025-09-15 09:16:00\n",
      "skipping date: 2025-09-15 13:25:00\n",
      "skipping date: 2025-09-15 13:08:00\n",
      "skipping date: 2025-09-15 12:14:00\n",
      "skipping date: 2025-09-15 11:24:00\n",
      "skipping date: 2025-09-15 10:24:00\n",
      "skipping date: 2025-09-15 10:42:00\n",
      "skipping date: 2025-09-15 11:39:00\n",
      "skipping date: 2025-09-15 09:41:00\n",
      "skipping date: 2025-09-15 11:30:00\n",
      "skipping date: 2025-09-15 09:31:00\n",
      "skipping date: 2025-09-15 09:09:00\n",
      "skipping date: 2025-09-15 07:33:00\n",
      "fetching fchg for Berlin Hbf (tief)\n",
      "skipping date: 2025-09-15 13:23:00\n",
      "skipping date: 2025-09-15 13:22:00\n",
      "skipping date: 2025-09-15 11:19:00\n",
      "skipping date: 2025-09-15 13:13:00\n",
      "skipping date: 2025-09-15 13:32:00\n",
      "skipping date: 2025-09-15 09:06:00\n",
      "skipping date: 2025-09-15 13:23:00\n",
      "skipping date: 2025-09-15 12:58:00\n",
      "skipping date: 2025-09-15 12:54:00\n",
      "skipping date: 2025-09-15 12:21:00\n",
      "skipping date: 2025-09-15 11:32:00\n",
      "skipping date: 2025-09-15 10:31:00\n",
      "skipping date: 2025-09-15 10:32:00\n",
      "skipping date: 2025-09-15 11:22:00\n",
      "skipping date: 2025-09-15 09:30:00\n",
      "skipping date: 2025-09-15 09:40:00\n",
      "skipping date: 2025-09-15 11:26:00\n",
      "skipping date: 2025-09-15 09:22:00\n",
      "skipping date: 2025-09-15 08:51:00\n",
      "skipping date: 2025-09-15 07:28:00\n",
      "fetching fchg for Berlin Hbf\n",
      "skipping date: 2025-09-15 12:28:00\n",
      "skipping date: 2025-09-15 12:02:00\n",
      "skipping date: 2025-09-15 13:52:00\n",
      "skipping date: 2025-09-15 13:16:00\n",
      "skipping date: 2025-09-15 13:16:00\n",
      "skipping date: 2025-09-15 10:04:00\n",
      "skipping date: 2025-09-15 12:37:00\n",
      "skipping date: 2025-09-15 12:43:00\n",
      "skipping date: 2025-09-15 12:10:00\n",
      "skipping date: 2025-09-15 12:16:00\n",
      "skipping date: 2025-09-15 11:43:00\n",
      "skipping date: 2025-09-15 11:43:00\n",
      "skipping date: 2025-09-15 06:05:00\n",
      "skipping date: 2025-09-15 10:41:00\n",
      "skipping date: 2025-09-15 09:42:00\n",
      "skipping date: 2025-09-15 09:42:00\n",
      "skipping date: 2025-09-15 08:41:00\n",
      "skipping date: 2025-09-15 08:24:00\n",
      "skipping date: 2025-09-15 08:00:00\n",
      "skipping date: 2025-09-15 07:41:00\n",
      "skipping date: 2025-09-15 07:42:00\n",
      "fetching fchg for Berlin-Spandau\n",
      "skipping date: 2025-09-15 12:48:00\n",
      "skipping date: 2025-09-15 13:37:00\n",
      "skipping date: 2025-09-15 12:21:00\n",
      "skipping date: 2025-09-15 11:33:00\n",
      "skipping date: 2025-09-15 13:49:00\n",
      "skipping date: 2025-09-15 13:35:00\n",
      "skipping date: 2025-09-15 13:11:00\n",
      "skipping date: 2025-09-15 10:22:00\n",
      "skipping date: 2025-09-15 13:02:00\n",
      "skipping date: 2025-09-15 13:02:00\n",
      "skipping date: 2025-09-15 13:01:00\n",
      "skipping date: 2025-09-15 12:45:00\n",
      "skipping date: 2025-09-15 12:37:00\n",
      "skipping date: 2025-09-15 12:29:00\n",
      "skipping date: 2025-09-15 12:21:00\n",
      "skipping date: 2025-09-15 11:45:00\n",
      "skipping date: 2025-09-15 10:42:00\n",
      "skipping date: 2025-09-15 10:22:00\n",
      "skipping date: 2025-09-15 11:13:00\n",
      "skipping date: 2025-09-15 09:18:00\n",
      "skipping date: 2025-09-15 09:48:00\n",
      "skipping date: 2025-09-15 12:01:00\n",
      "skipping date: 2025-09-15 12:01:00\n",
      "skipping date: 2025-09-15 12:01:00\n",
      "skipping date: 2025-09-15 06:24:00\n",
      "skipping date: 2025-09-15 11:02:00\n",
      "skipping date: 2025-09-15 10:02:00\n",
      "skipping date: 2025-09-15 10:02:00\n",
      "skipping date: 2025-09-15 09:00:00\n",
      "skipping date: 2025-09-15 08:40:00\n",
      "skipping date: 2025-09-15 08:19:00\n",
      "skipping date: 2025-09-15 07:58:00\n",
      "skipping date: 2025-09-15 07:58:00\n",
      "fetching fchg for Stendal Hbf\n",
      "skipping date: 2025-09-15 12:10:00\n",
      "skipping date: 2025-09-15 13:36:00\n",
      "skipping date: 2025-09-15 13:28:00\n",
      "skipping date: 2025-09-15 12:38:00\n",
      "skipping date: 2025-09-15 12:28:00\n",
      "skipping date: 2025-09-15 11:58:00\n",
      "skipping date: 2025-09-15 11:16:00\n",
      "skipping date: 2025-09-15 09:28:00\n",
      "skipping date: 2025-09-15 10:38:00\n",
      "skipping date: 2025-09-15 08:43:00\n",
      "skipping date: 2025-09-15 10:26:00\n",
      "[RateLimit] Limit erreicht (58/58s). Warte auf freien Slot...\n",
      "[RateLimit] Slot frei, Request wird gesendet.\n",
      "fetching fchg for Wolfsburg Hbf\n",
      "skipping date: 2025-09-15 13:44:00\n",
      "skipping date: 2025-09-15 12:38:00\n",
      "skipping date: 2025-09-15 13:55:00\n",
      "skipping date: 2025-09-15 13:17:00\n",
      "skipping date: 2025-09-15 13:17:00\n",
      "skipping date: 2025-09-15 12:54:00\n",
      "skipping date: 2025-09-15 12:54:00\n",
      "skipping date: 2025-09-15 12:32:00\n",
      "skipping date: 2025-09-15 12:07:00\n",
      "skipping date: 2025-09-15 12:07:00\n",
      "skipping date: 2025-09-15 11:57:00\n",
      "skipping date: 2025-09-15 10:57:00\n",
      "skipping date: 2025-09-15 10:57:00\n",
      "skipping date: 2025-09-15 10:51:00\n",
      "skipping date: 2025-09-15 09:56:00\n",
      "skipping date: 2025-09-15 09:37:00\n",
      "skipping date: 2025-09-15 08:53:00\n",
      "skipping date: 2025-09-15 08:53:00\n",
      "skipping date: 2025-09-15 06:28:00\n",
      "[RateLimit] Limit erreicht (58/58s). Warte auf freien Slot...\n",
      "[RateLimit] Slot frei, Request wird gesendet.\n",
      "fetching fchg for Bielefeld Hbf\n",
      "skipping date: 2025-09-15 13:30:00\n",
      "skipping date: 2025-09-15 11:31:00\n",
      "skipping date: 2025-09-15 10:47:00\n",
      "skipping date: 2025-09-15 13:28:00\n",
      "skipping date: 2025-09-15 11:31:00\n",
      "skipping date: 2025-09-15 10:51:00\n",
      "skipping date: 2025-09-15 09:18:00\n",
      "skipping date: 2025-09-15 08:45:00\n",
      "fetching fchg for Hamm(Westf)Hbf\n",
      "skipping date: 2025-09-15 12:56:00\n",
      "skipping date: 2025-09-15 10:50:00\n",
      "skipping date: 2025-09-15 11:21:00\n",
      "skipping date: 2025-09-15 13:30:00\n",
      "skipping date: 2025-09-15 12:49:00\n",
      "skipping date: 2025-09-15 12:49:00\n",
      "skipping date: 2025-09-15 11:07:00\n",
      "skipping date: 2025-09-15 11:26:00\n",
      "skipping date: 2025-09-15 10:48:00\n",
      "skipping date: 2025-09-15 10:49:00\n",
      "skipping date: 2025-09-15 09:25:00\n",
      "skipping date: 2025-09-15 09:20:00\n",
      "skipping date: 2025-09-15 08:46:00\n",
      "skipping date: 2025-09-15 08:16:00\n",
      "skipping date: 2025-09-15 08:16:00\n",
      "fetching fchg for Dortmund Hbf\n",
      "skipping date: 2025-09-15 12:39:00\n",
      "skipping date: 2025-09-15 10:32:00\n",
      "skipping date: 2025-09-15 11:44:00\n",
      "skipping date: 2025-09-15 13:27:00\n",
      "skipping date: 2025-09-15 13:49:00\n",
      "skipping date: 2025-09-15 13:16:00\n",
      "skipping date: 2025-09-15 12:52:00\n",
      "skipping date: 2025-09-15 12:21:00\n",
      "skipping date: 2025-09-15 10:45:00\n",
      "skipping date: 2025-09-15 09:39:00\n",
      "skipping date: 2025-09-15 11:34:00\n",
      "skipping date: 2025-09-15 12:15:00\n",
      "skipping date: 2025-09-15 06:36:00\n",
      "skipping date: 2025-09-15 11:11:00\n",
      "skipping date: 2025-09-15 10:43:00\n",
      "skipping date: 2025-09-15 10:00:00\n",
      "skipping date: 2025-09-15 08:48:00\n",
      "skipping date: 2025-09-15 08:26:00\n",
      "skipping date: 2025-09-15 08:23:00\n",
      "skipping date: 2025-09-15 07:54:00\n",
      "fetching fchg for Essen Hbf\n",
      "skipping date: 2025-09-16 06:58:00\n",
      "skipping date: 2025-09-17 06:58:00\n",
      "skipping date: 2025-09-15 13:16:00\n",
      "skipping date: 2025-09-15 13:55:00\n",
      "skipping date: 2025-09-15 13:56:00\n",
      "skipping date: 2025-09-15 13:50:00\n",
      "skipping date: 2025-09-15 09:58:00\n",
      "skipping date: 2025-09-15 13:01:00\n",
      "skipping date: 2025-09-15 12:48:00\n",
      "skipping date: 2025-09-15 12:06:00\n",
      "skipping date: 2025-09-15 11:09:00\n",
      "skipping date: 2025-09-15 11:57:00\n",
      "skipping date: 2025-09-15 09:58:00\n",
      "skipping date: 2025-09-15 05:58:00\n",
      "skipping date: 2025-09-15 05:58:00\n",
      "skipping date: 2025-09-15 08:00:00\n",
      "skipping date: 2025-09-15 11:46:00\n",
      "skipping date: 2025-09-15 10:16:00\n",
      "skipping date: 2025-09-15 09:23:00\n",
      "skipping date: 2025-09-15 08:15:00\n",
      "skipping date: 2025-09-15 07:23:00\n",
      "fetching fchg for Duisburg Hbf\n",
      "skipping date: 2025-09-16 06:45:00\n",
      "skipping date: 2025-09-15 13:12:00\n",
      "skipping date: 2025-09-17 06:45:00\n",
      "skipping date: 2025-09-15 13:03:00\n",
      "skipping date: 2025-09-15 13:36:00\n",
      "skipping date: 2025-09-15 13:15:00\n",
      "skipping date: 2025-09-15 09:42:00\n",
      "skipping date: 2025-09-15 11:54:00\n",
      "skipping date: 2025-09-15 11:22:00\n",
      "skipping date: 2025-09-15 12:10:00\n",
      "skipping date: 2025-09-15 09:42:00\n",
      "skipping date: 2025-09-15 05:45:00\n",
      "skipping date: 2025-09-15 05:44:00\n",
      "skipping date: 2025-09-15 07:45:00\n",
      "skipping date: 2025-09-15 08:45:00\n",
      "skipping date: 2025-09-15 11:59:00\n",
      "skipping date: 2025-09-15 10:25:00\n",
      "skipping date: 2025-09-15 10:03:00\n",
      "skipping date: 2025-09-15 09:10:00\n",
      "skipping date: 2025-09-15 09:07:00\n",
      "skipping date: 2025-09-15 08:35:00\n",
      "skipping date: 2025-09-15 07:10:00\n",
      "fetching fchg for Düsseldorf Hbf\n",
      "skipping date: 2025-09-16 06:31:00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     56\u001b[39m     timetable_fchg_stops = [timetable_fchg_stops]\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m timetable_fchg_stop \u001b[38;5;129;01min\u001b[39;00m timetable_fchg_stops:\n\u001b[32m     59\u001b[39m \n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# reset index after every change to not mess up updates\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     df_stoptimes = \u001b[43mdf_stoptimes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     64\u001b[39m         \u001b[38;5;66;03m# try to find id in stop_times\u001b[39;00m\n\u001b[32m     65\u001b[39m         stop_id = timetable_fchg_stop[\u001b[33m'\u001b[39m\u001b[33m@id\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\robin\\Documents\\github\\heidelberg-train-monitor\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:6424\u001b[39m, in \u001b[36mDataFrame.reset_index\u001b[39m\u001b[34m(self, level, drop, inplace, col_level, col_fill, allow_duplicates, names)\u001b[39m\n\u001b[32m   6422\u001b[39m     new_obj = \u001b[38;5;28mself\u001b[39m\n\u001b[32m   6423\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m6424\u001b[39m     new_obj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   6425\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_duplicates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default:\n\u001b[32m   6426\u001b[39m     allow_duplicates = validate_bool_kwarg(allow_duplicates, \u001b[33m\"\u001b[39m\u001b[33mallow_duplicates\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\robin\\Documents\\github\\heidelberg-train-monitor\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:6830\u001b[39m, in \u001b[36mNDFrame.copy\u001b[39m\u001b[34m(self, deep)\u001b[39m\n\u001b[32m   6681\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m   6682\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m, deep: bool_t | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mTrue\u001b[39;00m) -> Self:\n\u001b[32m   6683\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   6684\u001b[39m \u001b[33;03m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[32m   6685\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   6828\u001b[39m \u001b[33;03m    dtype: int64\u001b[39;00m\n\u001b[32m   6829\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6830\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6831\u001b[39m     \u001b[38;5;28mself\u001b[39m._clear_item_cache()\n\u001b[32m   6832\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(data, axes=data.axes).__finalize__(\n\u001b[32m   6833\u001b[39m         \u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mcopy\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6834\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\robin\\Documents\\github\\heidelberg-train-monitor\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:593\u001b[39m, in \u001b[36mBaseBlockManager.copy\u001b[39m\u001b[34m(self, deep)\u001b[39m\n\u001b[32m    590\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    591\u001b[39m         new_axes = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.axes)\n\u001b[32m--> \u001b[39m\u001b[32m593\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcopy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    594\u001b[39m res.axes = new_axes\n\u001b[32m    596\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ndim > \u001b[32m1\u001b[39m:\n\u001b[32m    597\u001b[39m     \u001b[38;5;66;03m# Avoid needing to re-compute these\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\robin\\Documents\\github\\heidelberg-train-monitor\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\robin\\Documents\\github\\heidelberg-train-monitor\\venv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:822\u001b[39m, in \u001b[36mBlock.copy\u001b[39m\u001b[34m(self, deep)\u001b[39m\n\u001b[32m    820\u001b[39m refs: BlockValuesRefs | \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m     values = values.copy()\n\u001b[32m    823\u001b[39m     refs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# request and process changes\n",
    "import requests\n",
    "import xmltodict\n",
    "import time\n",
    "import os.path as path\n",
    "\n",
    "# load envs\n",
    "db_timetables_base_url = getenv(\"db_timetables_base_url\")\n",
    "db_client_id = getenv(\"db_client_id\")\n",
    "db_client_secret = getenv(\"db_client_secret\")\n",
    "\n",
    "# for querying and matching planned stop times\n",
    "df_stoptimes_planned = pd.read_csv(PLANNED_STOPTIMES_PATH, dtype=str).dropna(how='all')\n",
    "df_stoptimes = df_stoptimes_planned.copy()\n",
    "\n",
    "for index, station_row in df_stations.iterrows():\n",
    "    try:\n",
    "        # for mutating and saving updated data\n",
    "        station_uic = station_row['station_uic']\n",
    "        station_name = station_row['station_name']\n",
    "            \n",
    "        # respect rate limiting\n",
    "        ratelimit.wait_for_slot()    \n",
    "            \n",
    "        print(f\"fetching fchg for {station_name}\")\n",
    "        \n",
    "        # prepare request headers\n",
    "        auth_headers = {\n",
    "            'DB-Client-Id': db_client_id,\n",
    "            'DB-Api-Key': db_client_secret\n",
    "        }\n",
    "        \n",
    "        # {hour:02} means print hour, fill (0) up to 2 (2) digits\n",
    "        url = f\"{db_timetables_base_url}/fchg/{station_uic}\"\n",
    "            \n",
    "            \n",
    "        response = requests.get(url=url, headers=auth_headers)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"skipping station {station_uic}, {response.status_code}\")\n",
    "            continue\n",
    "            \n",
    "            \n",
    "        # process response\n",
    "        timetable_fchg_dict = xmltodict.parse(response.content)\n",
    "        \n",
    "        # process response\n",
    "        timetable_fchg_dict = xmltodict.parse(response.content)\n",
    "        if timetable_fchg_dict['timetable'] is None:\n",
    "            print(f'empty timetable: skipping station {station_uic}')\n",
    "            continue\n",
    "        \n",
    "        timetable_fchg_stops = timetable_fchg_dict['timetable']['s']\n",
    "        \n",
    "        # if there is only one trip in the requested hour, the xml parser parses the timetable stop entry into a dict rather than a list\n",
    "        if not isinstance(timetable_fchg_stops, list):\n",
    "            timetable_fchg_stops = [timetable_fchg_stops]\n",
    "        \n",
    "        for timetable_fchg_stop in timetable_fchg_stops:\n",
    "            \n",
    "            # reset index after every change to not mess up updates\n",
    "            df_stoptimes = df_stoptimes.reset_index(drop=True)\n",
    "            \n",
    "            try:\n",
    "                # try to find id in stop_times\n",
    "                stop_id = timetable_fchg_stop['@id']\n",
    "                trip_id = extract_tripid_from_stopid(stop_id)\n",
    "                \n",
    "                planned_stop_times_for_id_and_station = df_stoptimes[(df_stoptimes['trip_id'] == trip_id) & (df_stoptimes['station_uic'] == station_uic)]\n",
    "                \n",
    "                # Fall 1 - Bahnhof + ID Bekannt -> Stop Update\n",
    "                if len(planned_stop_times_for_id_and_station) > 0:\n",
    "                    updated_stop_time = planned_stop_times_for_id_and_station.iloc[0].copy()\n",
    "                    stop_time_index_to_update = planned_stop_times_for_id_and_station.index[0]\n",
    "                    stop_time_position_to_update = df_stoptimes.index.get_loc(stop_time_index_to_update)\n",
    "                    \n",
    "                    # update arrival if changed\n",
    "                    if 'ar' in timetable_fchg_stop:\n",
    "                        arrival = timetable_fchg_stop['ar']\n",
    "                        \n",
    "                        # cancel if stop was canceled\n",
    "                        if '@cs' in arrival:\n",
    "                            if arrival['@cs'] == 'c':\n",
    "                                updated_stop_time['arrival_actual_dbdatetime'] = None\n",
    "                            \n",
    "                        # update if stop was not canceled\n",
    "                        elif '@ct' in arrival:\n",
    "                            updated_stop_time['arrival_actual_dbdatetime'] = arrival['@ct']\n",
    "                       \n",
    "                    \n",
    "                    # update departure if changed\n",
    "                    if 'dp' in timetable_fchg_stop:\n",
    "                        departure = timetable_fchg_stop['dp']\n",
    "                        \n",
    "                        # cancel if stop was canceled\n",
    "                        if '@cs' in departure:\n",
    "                            if departure['@cs'] == 'c':\n",
    "                                updated_stop_time['departure_actual_dbdatetime'] = None\n",
    "                            \n",
    "                        # update if stop was not canceled\n",
    "                        elif '@ct' in departure:\n",
    "                            updated_stop_time['departure_actual_dbdatetime'] = departure['@ct']\n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                    # save changed updated stop time\n",
    "                    df_stoptimes.iloc[stop_time_position_to_update] = updated_stop_time.reindex(df_stoptimes.columns)\n",
    "                  \n",
    "                \n",
    "                # Fall 2 - id +  Bahnhof unbekannt: Zusatzhalt\n",
    "                else:\n",
    "                    # if neither arrival nor departure exist, skip because there is no useful information. Can happen if the timetable sto ponly contains an information\n",
    "                    if 'ar' not in timetable_fchg_stop and 'dp' not in timetable_fchg_stop:\n",
    "                        continue\n",
    "                    \n",
    "                    \n",
    "                    category = None\n",
    "                    number = None\n",
    "                    \n",
    "                    # wenn trip label dabei ist, verwenden\n",
    "                    if 'tl' in timetable_fchg_stop:\n",
    "                        trip_label = timetable_fchg_stop['tl']\n",
    "                        category = trip_label['@c']\n",
    "                        number = trip_label['@n']\n",
    "                    \n",
    "                    # wenn trip label nicht dabei ist, versuchen den trip über die ID zu finden. Wenn gefunden -> category und number daher nehmen.\n",
    "                    # Wenn nicht gefunden -> Ignorieren, da Datensatz nicht gebildet werden kann, wahrscheinlich weil es ein Update für eine Regionalverkehrsfahrt ist\n",
    "                    else:\n",
    "                        stop_times_for_id = df_stoptimes[df_stoptimes['trip_id'] == trip_id]\n",
    "\n",
    "                        if len(stop_times_for_id) == 0:\n",
    "                            continue\n",
    "                        else:\n",
    "                            # all stop times for an id have the same category and number\n",
    "                            stop_time_for_id = stop_times_for_id.iloc[0]\n",
    "                            category = stop_time_for_id['category']\n",
    "                            number = stop_time_for_id['number']\n",
    "                    \n",
    "                    # wenn category nicht Fernverkehr, ignorieren\n",
    "                    if category not in FV_CATEGORIES:\n",
    "                        continue\n",
    "                    \n",
    "                    arrival_planned_dbdatetime = None\n",
    "                    arrival_actual_dbdatetime = None\n",
    "                    departure_planned_dbdatetime = None\n",
    "                    departure_actual_dbdatetime = None\n",
    "                    \n",
    "                    # process arrival if exists\n",
    "                    if 'ar' in timetable_fchg_stop:\n",
    "                        arrival = timetable_fchg_stop['ar']\n",
    "                        \n",
    "                        # if no times exist, skip because it is likely only an information like reversed coach order\n",
    "                        \n",
    "                        if '@pt' not in arrival and '@ct' not in arrival:\n",
    "                            continue\n",
    "                        \n",
    "                        # if only planned time exists, also use it as changed time\n",
    "                        if '@pt' in arrival and '@ct' not in arrival:\n",
    "                            arrival_planned_dbdatetime = arrival['@pt']\n",
    "                            arrival_actual_dbdatetime = arrival['@pt']\n",
    "                        \n",
    "                        # if only changed time exists, also use it as planned time\n",
    "                        if '@ct' in arrival and '@pt' not in arrival:\n",
    "                            arrival_planned_dbdatetime = arrival['@ct']                        \n",
    "                            arrival_actual_dbdatetime = arrival['@ct']                        \n",
    "                        \n",
    "                        # if both times exist use it normally\n",
    "                        if '@ct' in arrival and '@pt' in arrival:\n",
    "                            arrival_planned_dbdatetime = arrival['@pt']                        \n",
    "                            arrival_actual_dbdatetime = arrival['@ct']                        \n",
    "                        \n",
    "                    # process departure if exists\n",
    "                    if 'dp' in timetable_fchg_stop:\n",
    "                        departure = timetable_fchg_stop['dp']\n",
    "                        \n",
    "                        # if no times exist, skip because it is likely only an information like reversed coach order\n",
    "                        \n",
    "                        if '@pt' not in departure and '@ct' not in departure:\n",
    "                            continue\n",
    "                        \n",
    "                        # if only planned time exists, also use it as changed time\n",
    "                        if '@pt' in departure and '@ct' not in departure:\n",
    "                            departure_planned_dbdatetime = departure['@pt']\n",
    "                            departure_actual_dbdatetime = departure['@pt']\n",
    "                        \n",
    "                        # if only changed time exists, also use it as planned time\n",
    "                        if '@ct' in departure and '@pt' not in departure:\n",
    "                            departure_planned_dbdatetime = departure['@ct']                        \n",
    "                            departure_actual_dbdatetime = departure['@ct']                        \n",
    "                        \n",
    "                        # if both times exist use it normally\n",
    "                        if '@ct' in departure and '@pt' in departure:\n",
    "                            departure_planned_dbdatetime = departure['@pt']                        \n",
    "                            departure_actual_dbdatetime = departure['@ct']   \n",
    "                            \n",
    "                    # request timestamp would be the hour in which the trains planned departure or arrival is. So take the planned departure and if not exists the planned \n",
    "                    # arrival and just cut of the minutes\n",
    "                    request_timestamp = arrival_planned_dbdatetime[:-2] if arrival_planned_dbdatetime is not None else departure_planned_dbdatetime[:-2]\n",
    "                    \n",
    "                    \n",
    "                    # ignore the entry, if the actual arrival / departure is outside of the +- 5 hour window from now. Sometimes updates from the last day that still remain \n",
    "                    # in the dataset can mess up calculation, especially for long running night trains\n",
    "                    actual_arrival_or_departure_dbdatetime = arrival_actual_dbdatetime if arrival_actual_dbdatetime is not None else departure_actual_dbdatetime\n",
    "                    actual_arrival_or_departure = DBDatetimeToDatetime(actual_arrival_or_departure_dbdatetime)\n",
    "                    \n",
    "                    in_five_hours = datetime.datetime.now() + datetime.timedelta(hours=5)\n",
    "                    five_hours_ago = datetime.datetime.now() - datetime.timedelta(hours=5)\n",
    "                    \n",
    "                    if not(five_hours_ago < actual_arrival_or_departure < in_five_hours):\n",
    "                        print(f\"skipping date: {actual_arrival_or_departure}\")\n",
    "                        continue    \n",
    "                            \n",
    "                            \n",
    "                    # wenn category Fernverkehr, neuen Stop anlegen\n",
    "                    additional_stop = pd.DataFrame(data={\n",
    "                        'trip_id': [trip_id],\n",
    "                        'category': [category],\n",
    "                        'number': [number],\n",
    "                        'station_name': [station_name],\n",
    "                        'station_uic': [station_uic],\n",
    "                        'arrival_planned_dbdatetime': [arrival_planned_dbdatetime],\n",
    "                        'departure_planned_dbdatetime': [departure_planned_dbdatetime],\n",
    "                        'arrival_actual_dbdatetime': [arrival_actual_dbdatetime],\n",
    "                        'departure_actual_dbdatetime': [departure_actual_dbdatetime],\n",
    "                        'request_timestamp': [request_timestamp]})\n",
    "                    \n",
    "                    df_stoptimes = pd.concat([df_stoptimes, additional_stop])\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(\"error during processing timetable stop}\", timetable_fchg_stop)\n",
    "                print(e)\n",
    "                \n",
    "\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    \n",
    "# POSTPROCESS BEFORE SAVING\n",
    "\n",
    "# remove duplicates\n",
    "# duplicates can occur when a train arrives before and departs after the full hour, because in this case the train will be included in both slices\n",
    "\n",
    "df_stoptimes = df_stoptimes.drop_duplicates(subset=['trip_id', 'station_uic','departure_planned_dbdatetime','departure_actual_dbdatetime'])\n",
    "\n",
    "# remove stoptimes without an arrival or a departure (can happen when a stop is cancelled)\n",
    "df_stoptimes = df_stoptimes.dropna(subset=['arrival_actual_dbdatetime','departure_actual_dbdatetime'], how='all')\n",
    "\n",
    "    \n",
    "# add departure / arrival where necessary. Every stop needs a departure and arrival for animation to work \n",
    "# set arrival to departure where arrival is na\n",
    "departure_actual_isna_mask =  df_stoptimes['departure_actual_dbdatetime'].isna()\n",
    "df_stoptimes.loc[departure_actual_isna_mask, 'departure_actual_dbdatetime'] = df_stoptimes[departure_actual_isna_mask]['arrival_actual_dbdatetime']\n",
    "\n",
    "departure_planned_isna_mask =  df_stoptimes['departure_planned_dbdatetime'].isna()\n",
    "df_stoptimes.loc[departure_planned_isna_mask, 'departure_planned_dbdatetime'] = df_stoptimes[departure_planned_isna_mask]['arrival_planned_dbdatetime']\n",
    "\n",
    "\n",
    "arrival_actual_isna_mask =  df_stoptimes['arrival_actual_dbdatetime'].isna()\n",
    "df_stoptimes.loc[arrival_actual_isna_mask, 'arrival_actual_dbdatetime'] = df_stoptimes[arrival_actual_isna_mask]['departure_actual_dbdatetime']\n",
    "\n",
    "arrival_planned_isna_mask =  df_stoptimes['arrival_planned_dbdatetime'].isna()\n",
    "df_stoptimes.loc[arrival_planned_isna_mask, 'arrival_planned_dbdatetime'] = df_stoptimes[arrival_planned_isna_mask]['departure_planned_dbdatetime']\n",
    "\n",
    "# sort\n",
    "df_stoptimes = df_stoptimes.sort_values(by=['trip_id','departure_actual_dbdatetime'])\n",
    "\n",
    "# convert arrival and departure to datetimes\n",
    "df_stoptimes['arrival_planned'] = df_stoptimes['arrival_planned_dbdatetime'].map(DBDatetimeToDatetime)\n",
    "df_stoptimes['departure_planned'] = df_stoptimes['departure_planned_dbdatetime'].map(DBDatetimeToDatetime)\n",
    "df_stoptimes['arrival_actual'] = df_stoptimes['arrival_actual_dbdatetime'].map(DBDatetimeToDatetime)\n",
    "df_stoptimes['departure_actual'] = df_stoptimes['departure_actual_dbdatetime'].map(DBDatetimeToDatetime)  \n",
    "\n",
    "# compute arrival and departure delay in minutes (min: 0)\n",
    "def compute_arrival_delay(row):\n",
    "    delta:datetime.timedelta = row['arrival_actual'] - row['arrival_planned']\n",
    "    delay = max(int(delta.total_seconds() / 60),0)\n",
    "    return delay\n",
    "\n",
    "def compute_departure_delay(row):\n",
    "    delta:datetime.timedelta = row['departure_actual'] - row['departure_planned']\n",
    "    delay = max(int(delta.total_seconds() / 60),0)\n",
    "    return delay\n",
    "\n",
    "df_stoptimes['arrival_delay'] = df_stoptimes.apply(compute_arrival_delay, axis=1)  \n",
    "df_stoptimes['departure_delay'] = df_stoptimes.apply(compute_departure_delay, axis=1)  \n",
    "\n",
    "# rename actual columns for easier and less confusing processing later on\n",
    "df_stoptimes['arrival'] = df_stoptimes.loc[:,'arrival_actual']\n",
    "df_stoptimes['departure'] = df_stoptimes.loc[:,'departure_actual']\n",
    "        \n",
    "# remove now uneeded old arrival and departure columns \n",
    "df_stoptimes=df_stoptimes.drop(labels=['arrival_planned_dbdatetime','departure_planned_dbdatetime','arrival_actual_dbdatetime', 'departure_actual_dbdatetime','arrival_planned', 'departure_planned', 'arrival_actual', 'departure_actual'], axis=1)\n",
    "\n",
    "\n",
    "# save\n",
    "df_stoptimes.to_csv(STOPTIMES_PATH, index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83774ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
